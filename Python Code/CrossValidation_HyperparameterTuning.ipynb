{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b533209-de4c-4e24-b29d-230c636e26e5",
   "metadata": {},
   "source": [
    "# Assignment 2: 75 points (+ 10 extra credit)\n",
    "# Cross Validation and Hyperparameter Tuning for CIFAR-10\n",
    "\n",
    "### IMPORTANT: \n",
    "#### You MUST read everything in tnis notebook CAREFULLY, including ALL code comments.  If you do not, then you may easily make mistakes.\n",
    "\n",
    "In Week 1 we discussed Cross Validation and in Week 2 we discuss Hyperparameter Tuning.  In this assignment we will learn how to use Cross Validation to help you perform Hyperparameter Tuning.  Be sure to review the class slides if you need to.\n",
    "\n",
    "You will need to consult the following documentation URLs in order to conplete this assignment:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105de21f-3709-4f2d-8ed9-68042cf1dacc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1: 5 points.  Set up environment\n",
    "\n",
    "# As we did for Assignment 1, you will need the following imports.   \n",
    "# If some of these do not import properly, you may need to install them\n",
    "# and then re-run this cell.\n",
    "\n",
    "import keras\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "import beepy              as bp    # for audio alerts\n",
    "import matplotlib         as mpl   # for graphing\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy              as np    # for fast vector and matrix operations\n",
    "import pandas             as pd\n",
    "\n",
    "from keras.datasets          import cifar10  # The Keras package comes with several datasets, incl. CIFAR10\n",
    "from pprint                  import pprint   # pprint means 'pretty print'.  You'll see why when we use it.\n",
    "from sklearn.linear_model    import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "\n",
    "np.random.seed(42) # for reproducibility\n",
    "# The next line tells Jupyter to show all plots inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62fd83b-8238-4e68-a1fe-fcba2fdb1ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: 10 points\n",
    "\n",
    "# Load and prepare the CIFAR-10 dataset.\n",
    "# You already did all of this in Assignment 1, so you can go back to that\n",
    "# assignment and copy what you need into this cell.\n",
    "# Be sure to include:\n",
    "# 1. Setting the values of: X_train, y_train, X_test, and y_test\n",
    "#    with X_train and X_test as normalized 'float32' numbers,\n",
    "#    and with y_train and y_test converted to 1-dimensional vectors\n",
    "# 3. Creation of X_train_flat and X_test_flat by reshaping X_train and X_test\n",
    "#\n",
    "# Again, ALL of this can be found in Assignment 1, so it should be\n",
    "# an easy 10 points for you here.\n",
    "\n",
    "# This cell needs: \n",
    "# import numpy as np\n",
    "# from   keras.datasets import cifar10\n",
    "\n",
    "np.random.seed(42) # Make this notebook's output stable across runs\n",
    "\n",
    "#################### Insert your code below for 10 points ###############\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "X_train /= 255.0                      # The largest number is 255, and the smallest 0\n",
    "X_test  /= 255.0                      # So this division will normalize the data.\n",
    "\n",
    "X_train_flat = X_train.reshape(50000, X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "X_test_flat  = X_test.reshape(10000, X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "\n",
    "# We also have to use ravel to change the target values (the values we want to predict). \n",
    "# e.g. y_train has an original shape of (50000, 1), i.e. a 2-dimensional matrix, albeit with only one column.\n",
    "# If we keep it in that shape, it will cause our modeling software to complain because \n",
    "# it wants the target values to appear as a 1-dimensional vector, which is what ravel will do for us.\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "'Done' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5368e1ad-b620-48a7-a0a6-d33173b40a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/matthewivezaj/Desktop/Anaconda/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:\t 234.9292 seconds\n",
      "Best params:\t {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "Best estimator:\t SGDClassifier(alpha=0.1, loss='modified_huber', max_iter=30, n_jobs=-1,\n",
      "              random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Task 3: 15 points\n",
    "\n",
    "# Use CROSS VALIDATION to perform GRID SEARCH\n",
    "\n",
    "# We have not yet studied Regularization, but we will later in this class.\n",
    "# Just know that it's an important concept and there are hyperparameters\n",
    "# to control it.  This assignment will help find good values for it. \n",
    "\n",
    "# We use grid search to find better values than the default for the hyperparameters \n",
    "# 'penalty' (for regularization, with default l2), 'alpha' (default 0.0001), \n",
    "# which controls the strength of regularization, and loss functions (default 'hinge')\n",
    "\n",
    "# You may need to consult the following to complete this cell:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "# This cell needs the additional imports:\n",
    "# import time\n",
    "# from sklearn.linear_model     import SGDClassifier\n",
    "# nfrom sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# First, set up your grid in the form of a Python dictionary.\n",
    "# Each key is the string name of a hyperparameter, and its value\n",
    "# is a list of values for that hyperparameter to use:\n",
    "# For key 'loss', use values 'hinge' and 'modified_huber'\n",
    "# For key 'penalty', use values 'l1' and 'l2'.  Those are the names\n",
    "#    of two different regularizations that we'll study later.\n",
    "# For key 'alpha', use the values: 0.0001, 0.001, 0.01, and 0.1\n",
    "#    The value of alpha controls the strength of the regularization\n",
    "\n",
    "# I have added the code already for the 'loss' functions.\n",
    "# You need to add the code for 'penalty' and 'alpha'.\n",
    "\n",
    "#################### Insert your code below for 5 points ##################\n",
    "hp_grid    = {'loss':    ['hinge', 'modified_huber'], # Default is hinge\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'alpha':   [0.0001, 0.001, 0.01, 0.1]\n",
    "             } \n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# Note that with this grid, we will be building 16 models (2 * 2 * 4) \n",
    "# And all 16 models will be trained 3 times because of the 3-fold cross-validation\n",
    "\n",
    "# Next, call SGDClassifier and pass it these arguments: \n",
    "# (look at the documentation for the exact argument names and perhaps other values)\n",
    "# A maximum of 30 iterations. \n",
    "\n",
    "# You will likely see warning messages suggesting\n",
    "# that you increase the number of iterations.  In the 'real world' you\n",
    "# would probably use the default of 1000 iterations, but I'm having you\n",
    "# use only 30 to save you a lot of time, while still getting practice.\n",
    "\n",
    "# The maximum number of jobs (processors).  (We have already used this in Assignment 1)\n",
    "# A random state of 42\n",
    "# Save the classifer into the variable 'sgd'\n",
    "\n",
    "# Then call GridSearchCV to create your grid search object, passing it the arguments:\n",
    "# sgd\n",
    "# hp_grid that you created above\n",
    "# and a setting to set GridSearchCV to do 3-fold cross validation, again to save time\n",
    "# over the default of 5-fold. \n",
    "# Save your grid search in the variable gridSearch\n",
    "\n",
    "#################### Insert your code below for 5 points ##################\n",
    "sgd        =     SGDClassifier(max_iter=30, n_jobs=-1, random_state=42)     \n",
    "gridSearch =     GridSearchCV(sgd, hp_grid, cv=3)\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# The variable gridSearch now encapsulates both your SGDClassifer as well as your \n",
    "# hyperparameter grid.  You can treat it just as if it was the name of a model\n",
    "# that now needs to be fitted to the data.  The2efore, call gridSearch with its fit method\n",
    "# and pass it the two arguments X_train_flat and y_train\n",
    "# I have set up some timing, print statements and an audio alert for you.\n",
    "\n",
    "startTime = time.perf_counter()                               # Capture the starting time \n",
    "\n",
    "########### Insert your grid search code below for 5 points ################\n",
    "gridSearch.fit(X_train_flat, y_train)\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "stopTime  = time.perf_counter()                               # Capture the ending time\n",
    "print(f'Elapsed time:\\t {stopTime - startTime:0.4f} seconds') # Compute and display the time difference\n",
    "\n",
    "print('Best params:\\t', gridSearch.best_params_)              # Let's look at the best hyperparameter values.\n",
    "print('Best estimator:\\t', gridSearch.best_estimator_)        # You can get additional info this way, \n",
    "                                                              #including the best model's hyperparameter settings. \n",
    "bp.beep(sound='ping')                                         # To get your attention when this code is done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342eaf90-7350-4aca-ba02-fac1964de02b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain print version of grid results: \n",
      "\n",
      " {'mean_fit_time': array([7.8221519 , 4.05920045, 8.58809861, 4.04238025, 3.31697234,\n",
      "       4.15598726, 8.80018234, 4.21493864, 1.89517617, 3.96844935,\n",
      "       6.56839379, 5.32015308, 1.84254694, 1.96242428, 3.04668903,\n",
      "       5.36755904]), 'std_fit_time': array([0.02033203, 0.01659742, 0.06956068, 0.01548768, 0.06983328,\n",
      "       0.01964309, 0.46369796, 0.00755246, 0.01677323, 0.04872959,\n",
      "       1.07619215, 0.01790813, 0.00685765, 0.09414567, 0.00616069,\n",
      "       0.17603815]), 'mean_score_time': array([0.03847869, 0.03172286, 0.0284543 , 0.03680428, 0.04606692,\n",
      "       0.03740414, 0.03186742, 0.030605  , 0.03459175, 0.03001968,\n",
      "       0.03066969, 0.02849825, 0.03420432, 0.03267741, 0.02885365,\n",
      "       0.03096652]), 'std_score_time': array([0.0059816 , 0.00219589, 0.00178622, 0.00474676, 0.00498781,\n",
      "       0.00551577, 0.00298861, 0.00111484, 0.01088469, 0.00091648,\n",
      "       0.00195335, 0.00014131, 0.00447988, 0.0054345 , 0.00437231,\n",
      "       0.00373838]), 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_loss': masked_array(data=['hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l1'}, {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l1'}, {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'}, {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'}, {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}, {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}, {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'}, {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l1'}, {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'}, {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'}, {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}, {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}, {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}], 'split0_test_score': array([0.29891402, 0.2698146 , 0.28181436, 0.33641327, 0.2247555 ,\n",
      "       0.34325313, 0.28451431, 0.299934  , 0.1047579 , 0.32951341,\n",
      "       0.31343373, 0.34343313, 0.100018  , 0.35867283, 0.100018  ,\n",
      "       0.38075238]), 'split1_test_score': array([0.29189416, 0.29237415, 0.29729405, 0.31361373, 0.24665507,\n",
      "       0.30797384, 0.29195416, 0.2749145 , 0.099958  , 0.37241255,\n",
      "       0.30671387, 0.34211316, 0.099958  , 0.32645347, 0.100018  ,\n",
      "       0.37307254]), 'split2_test_score': array([0.26161046, 0.2323893 , 0.26947078, 0.26671067, 0.26161046,\n",
      "       0.28483139, 0.27367095, 0.2700708 , 0.10152406, 0.30517221,\n",
      "       0.30199208, 0.29707188, 0.099964  , 0.30541222, 0.100024  ,\n",
      "       0.37075483]), 'mean_test_score': array([0.28413955, 0.26485935, 0.28285973, 0.30557922, 0.24434035,\n",
      "       0.31201946, 0.28337981, 0.28163977, 0.10207999, 0.33569939,\n",
      "       0.30737989, 0.32753939, 0.09998   , 0.3301795 , 0.10002   ,\n",
      "       0.37485992]), 'std_test_score': array([1.61861949e-02, 2.47381172e-02, 1.13828309e-02, 2.90175600e-02,\n",
      "       1.51347385e-02, 2.40215213e-02, 7.50707682e-03, 1.30862413e-02,\n",
      "       1.99859309e-03, 2.77970712e-02, 4.69471629e-03, 2.15505198e-02,\n",
      "       2.69813625e-05, 2.19025971e-02, 2.82904939e-06, 4.27268994e-03]), 'rank_test_score': array([ 8, 12, 10,  7, 13,  5,  9, 11, 14,  2,  6,  4, 16,  3, 15,  1],\n",
      "      dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# This code is adapted from Geron's chapter 2 cell, where he says: \n",
    "# \"Let's look at the score of each hyperparameter combination tested during the grid search:\"\n",
    "\n",
    "gridResults = gridSearch.cv_results_\n",
    "\n",
    "# show everything captured in the grid search cross-validation \n",
    "print('Plain print version of grid results: \\n\\n', gridResults)  # This will be kind of messy and hard to read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d759bc-dce8-465c-8bbf-8df7d740ae1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty Printed version:\n",
      "\n",
      "{'mean_fit_time': array([7.8221519 , 4.05920045, 8.58809861, 4.04238025, 3.31697234,\n",
      "       4.15598726, 8.80018234, 4.21493864, 1.89517617, 3.96844935,\n",
      "       6.56839379, 5.32015308, 1.84254694, 1.96242428, 3.04668903,\n",
      "       5.36755904]),\n",
      " 'mean_score_time': array([0.03847869, 0.03172286, 0.0284543 , 0.03680428, 0.04606692,\n",
      "       0.03740414, 0.03186742, 0.030605  , 0.03459175, 0.03001968,\n",
      "       0.03066969, 0.02849825, 0.03420432, 0.03267741, 0.02885365,\n",
      "       0.03096652]),\n",
      " 'mean_test_score': array([0.28413955, 0.26485935, 0.28285973, 0.30557922, 0.24434035,\n",
      "       0.31201946, 0.28337981, 0.28163977, 0.10207999, 0.33569939,\n",
      "       0.30737989, 0.32753939, 0.09998   , 0.3301795 , 0.10002   ,\n",
      "       0.37485992]),\n",
      " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_loss': masked_array(data=['hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber',\n",
      "                   'hinge', 'hinge', 'modified_huber', 'modified_huber'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l1'},\n",
      "            {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'},\n",
      "            {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
      "            {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
      "            {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'},\n",
      "            {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'},\n",
      "            {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
      "            {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
      "            {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'},\n",
      "            {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'},\n",
      "            {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
      "            {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
      "            {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'},\n",
      "            {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'},\n",
      "            {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
      "            {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}],\n",
      " 'rank_test_score': array([ 8, 12, 10,  7, 13,  5,  9, 11, 14,  2,  6,  4, 16,  3, 15,  1],\n",
      "      dtype=int32),\n",
      " 'split0_test_score': array([0.29891402, 0.2698146 , 0.28181436, 0.33641327, 0.2247555 ,\n",
      "       0.34325313, 0.28451431, 0.299934  , 0.1047579 , 0.32951341,\n",
      "       0.31343373, 0.34343313, 0.100018  , 0.35867283, 0.100018  ,\n",
      "       0.38075238]),\n",
      " 'split1_test_score': array([0.29189416, 0.29237415, 0.29729405, 0.31361373, 0.24665507,\n",
      "       0.30797384, 0.29195416, 0.2749145 , 0.099958  , 0.37241255,\n",
      "       0.30671387, 0.34211316, 0.099958  , 0.32645347, 0.100018  ,\n",
      "       0.37307254]),\n",
      " 'split2_test_score': array([0.26161046, 0.2323893 , 0.26947078, 0.26671067, 0.26161046,\n",
      "       0.28483139, 0.27367095, 0.2700708 , 0.10152406, 0.30517221,\n",
      "       0.30199208, 0.29707188, 0.099964  , 0.30541222, 0.100024  ,\n",
      "       0.37075483]),\n",
      " 'std_fit_time': array([0.02033203, 0.01659742, 0.06956068, 0.01548768, 0.06983328,\n",
      "       0.01964309, 0.46369796, 0.00755246, 0.01677323, 0.04872959,\n",
      "       1.07619215, 0.01790813, 0.00685765, 0.09414567, 0.00616069,\n",
      "       0.17603815]),\n",
      " 'std_score_time': array([0.0059816 , 0.00219589, 0.00178622, 0.00474676, 0.00498781,\n",
      "       0.00551577, 0.00298861, 0.00111484, 0.01088469, 0.00091648,\n",
      "       0.00195335, 0.00014131, 0.00447988, 0.0054345 , 0.00437231,\n",
      "       0.00373838]),\n",
      " 'std_test_score': array([1.61861949e-02, 2.47381172e-02, 1.13828309e-02, 2.90175600e-02,\n",
      "       1.51347385e-02, 2.40215213e-02, 7.50707682e-03, 1.30862413e-02,\n",
      "       1.99859309e-03, 2.77970712e-02, 4.69471629e-03, 2.15505198e-02,\n",
      "       2.69813625e-05, 2.19025971e-02, 2.82904939e-06, 4.27268994e-03])}\n"
     ]
    }
   ],
   "source": [
    "# Task 4: 5 points\n",
    "\n",
    "# 'pretty print' the gridResults and compare to the plain print version above\n",
    "# from pprint import pprint   # pprint means 'pretty print'\n",
    "\n",
    "print('Pretty Printed version:\\n')\n",
    "\n",
    " # Just call the 'pprint' function and pass it gridResults as the argument\n",
    "#################### Insert your code below for 5 points ##################\n",
    "pprint(gridResults)\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# You should notice that it's easier to read than the preious cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587398c8-bd07-436b-8082-53163d95a458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2841395494183 {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.2648593505988995 {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.2828597322209322 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.30557922262891596 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.24434034540238034 {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.31201945623874033 {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.2833798058228203 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.28163976862068424 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.10207998888144161 {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.33569938945634864 {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.3073798922437488 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.3275393906498445 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.0999799996799776 {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.3301795046542367 {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.1000200000800176 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.3748599178982459 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# In the preceding cell, notice that the 'params': section shows the hyperparameter \n",
    "# settings for each of the grid search models and 'mean_test_score': \n",
    "# gives the average of the cross validation splits for each of the 16 models\n",
    "\n",
    "# Here are the mean test scores and their hyperparameter values for the models.\n",
    "for test_score, params in zip(gridResults[\"mean_test_score\"], gridResults[\"params\"]):\n",
    "    print(test_score, params)\n",
    "    \n",
    "# Just look at the average test score at the beginning of each line,\n",
    "# and you will notice that the largest value is the line that shows\n",
    "# what you saw above as output for the best parameter values:\n",
    "# print('Best params:\\t', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494aa474-625d-4e11-b786-fc637b3453bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.741982</td>\n",
       "      <td>0.058010</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...</td>\n",
       "      <td>0.298914</td>\n",
       "      <td>0.291894</td>\n",
       "      <td>0.261610</td>\n",
       "      <td>0.284140</td>\n",
       "      <td>0.016186</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.068912</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...</td>\n",
       "      <td>0.269815</td>\n",
       "      <td>0.292374</td>\n",
       "      <td>0.232389</td>\n",
       "      <td>0.264859</td>\n",
       "      <td>0.024738</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.720941</td>\n",
       "      <td>0.058463</td>\n",
       "      <td>0.029858</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'modified_huber', 'p...</td>\n",
       "      <td>0.281814</td>\n",
       "      <td>0.297294</td>\n",
       "      <td>0.269471</td>\n",
       "      <td>0.282860</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.108213</td>\n",
       "      <td>0.068133</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'modified_huber', 'p...</td>\n",
       "      <td>0.336413</td>\n",
       "      <td>0.313614</td>\n",
       "      <td>0.266711</td>\n",
       "      <td>0.305579</td>\n",
       "      <td>0.029018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.386056</td>\n",
       "      <td>0.095332</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>0.224756</td>\n",
       "      <td>0.246655</td>\n",
       "      <td>0.261610</td>\n",
       "      <td>0.244340</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.154820</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>0.343253</td>\n",
       "      <td>0.307974</td>\n",
       "      <td>0.284831</td>\n",
       "      <td>0.312019</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.859801</td>\n",
       "      <td>0.478158</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>0.284514</td>\n",
       "      <td>0.291954</td>\n",
       "      <td>0.273671</td>\n",
       "      <td>0.283380</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.213021</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>0.299934</td>\n",
       "      <td>0.274915</td>\n",
       "      <td>0.270071</td>\n",
       "      <td>0.281640</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.896812</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.032462</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'}</td>\n",
       "      <td>0.104758</td>\n",
       "      <td>0.099958</td>\n",
       "      <td>0.101524</td>\n",
       "      <td>0.102080</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.944738</td>\n",
       "      <td>0.042876</td>\n",
       "      <td>0.032075</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'}</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.372413</td>\n",
       "      <td>0.305172</td>\n",
       "      <td>0.335699</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.544787</td>\n",
       "      <td>1.083312</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.01</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'modified_huber', 'pen...</td>\n",
       "      <td>0.313434</td>\n",
       "      <td>0.306714</td>\n",
       "      <td>0.301992</td>\n",
       "      <td>0.307380</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.304007</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.01</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'modified_huber', 'pen...</td>\n",
       "      <td>0.343433</td>\n",
       "      <td>0.342113</td>\n",
       "      <td>0.297072</td>\n",
       "      <td>0.327539</td>\n",
       "      <td>0.021551</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.912157</td>\n",
       "      <td>0.041105</td>\n",
       "      <td>0.029761</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'}</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.099958</td>\n",
       "      <td>0.099964</td>\n",
       "      <td>0.099980</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.959849</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.035623</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}</td>\n",
       "      <td>0.358673</td>\n",
       "      <td>0.326453</td>\n",
       "      <td>0.305412</td>\n",
       "      <td>0.330180</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.102814</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>0.031768</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.1</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'loss': 'modified_huber', 'pena...</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.100024</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.377514</td>\n",
       "      <td>0.188903</td>\n",
       "      <td>0.029078</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.1</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'loss': 'modified_huber', 'pena...</td>\n",
       "      <td>0.380752</td>\n",
       "      <td>0.373073</td>\n",
       "      <td>0.370755</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        7.741982      0.058010         0.050847        0.003287      0.0001   \n",
       "1        4.068912      0.040881         0.044123        0.013350      0.0001   \n",
       "2        8.720941      0.058463         0.029858        0.001979      0.0001   \n",
       "3        4.108213      0.068133         0.035931        0.006869      0.0001   \n",
       "4        3.386056      0.095332         0.032073        0.005512       0.001   \n",
       "5        4.154820      0.011835         0.037901        0.002727       0.001   \n",
       "6        8.859801      0.478158         0.034725        0.010017       0.001   \n",
       "7        4.213021      0.018744         0.028877        0.001055       0.001   \n",
       "8        1.896812      0.011559         0.032462        0.007012        0.01   \n",
       "9        3.944738      0.042876         0.032075        0.002323        0.01   \n",
       "10       6.544787      1.083312         0.028674        0.002680        0.01   \n",
       "11       5.304007      0.009892         0.032280        0.003024        0.01   \n",
       "12       1.912157      0.041105         0.029761        0.001406         0.1   \n",
       "13       1.959849      0.093014         0.035623        0.005230         0.1   \n",
       "14       3.102814      0.025713         0.031768        0.002817         0.1   \n",
       "15       5.377514      0.188903         0.029078        0.000655         0.1   \n",
       "\n",
       "        param_loss param_penalty  \\\n",
       "0            hinge            l1   \n",
       "1            hinge            l2   \n",
       "2   modified_huber            l1   \n",
       "3   modified_huber            l2   \n",
       "4            hinge            l1   \n",
       "5            hinge            l2   \n",
       "6   modified_huber            l1   \n",
       "7   modified_huber            l2   \n",
       "8            hinge            l1   \n",
       "9            hinge            l2   \n",
       "10  modified_huber            l1   \n",
       "11  modified_huber            l2   \n",
       "12           hinge            l1   \n",
       "13           hinge            l2   \n",
       "14  modified_huber            l1   \n",
       "15  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...           0.298914   \n",
       "1   {'alpha': 0.0001, 'loss': 'hinge', 'penalty': ...           0.269815   \n",
       "2   {'alpha': 0.0001, 'loss': 'modified_huber', 'p...           0.281814   \n",
       "3   {'alpha': 0.0001, 'loss': 'modified_huber', 'p...           0.336413   \n",
       "4   {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...           0.224756   \n",
       "5   {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...           0.343253   \n",
       "6   {'alpha': 0.001, 'loss': 'modified_huber', 'pe...           0.284514   \n",
       "7   {'alpha': 0.001, 'loss': 'modified_huber', 'pe...           0.299934   \n",
       "8   {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'}           0.104758   \n",
       "9   {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'}           0.329513   \n",
       "10  {'alpha': 0.01, 'loss': 'modified_huber', 'pen...           0.313434   \n",
       "11  {'alpha': 0.01, 'loss': 'modified_huber', 'pen...           0.343433   \n",
       "12   {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'}           0.100018   \n",
       "13   {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}           0.358673   \n",
       "14  {'alpha': 0.1, 'loss': 'modified_huber', 'pena...           0.100018   \n",
       "15  {'alpha': 0.1, 'loss': 'modified_huber', 'pena...           0.380752   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.291894           0.261610         0.284140        0.016186   \n",
       "1            0.292374           0.232389         0.264859        0.024738   \n",
       "2            0.297294           0.269471         0.282860        0.011383   \n",
       "3            0.313614           0.266711         0.305579        0.029018   \n",
       "4            0.246655           0.261610         0.244340        0.015135   \n",
       "5            0.307974           0.284831         0.312019        0.024022   \n",
       "6            0.291954           0.273671         0.283380        0.007507   \n",
       "7            0.274915           0.270071         0.281640        0.013086   \n",
       "8            0.099958           0.101524         0.102080        0.001999   \n",
       "9            0.372413           0.305172         0.335699        0.027797   \n",
       "10           0.306714           0.301992         0.307380        0.004695   \n",
       "11           0.342113           0.297072         0.327539        0.021551   \n",
       "12           0.099958           0.099964         0.099980        0.000027   \n",
       "13           0.326453           0.305412         0.330180        0.021903   \n",
       "14           0.100018           0.100024         0.100020        0.000003   \n",
       "15           0.373073           0.370755         0.374860        0.004273   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 8  \n",
       "1                12  \n",
       "2                10  \n",
       "3                 7  \n",
       "4                13  \n",
       "5                 5  \n",
       "6                 9  \n",
       "7                11  \n",
       "8                14  \n",
       "9                 2  \n",
       "10                6  \n",
       "11                4  \n",
       "12               16  \n",
       "13                3  \n",
       "14               15  \n",
       "15                1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the best readability put the grid search results into a pandas dataframe,\n",
    "# and you will see all available information\n",
    "# import pandas as pd\n",
    "pd.DataFrame(gridSearch.cv_results_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febd5284-c49b-4ff4-a59c-b64acc9aabfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed Time Default:           10 seconds\n",
      "Default Model Accuracy:  0.451\n"
     ]
    }
   ],
   "source": [
    "# Task 5: 10 points   \n",
    "\n",
    "# Build another model using the best combination of hyperparameters\n",
    "# from your cross validation grid search in the earlier cell.\n",
    "# Also use:\n",
    "# max_iter     = 1000 # The default, for valid comparison with Assignment 1 \n",
    "# n_jobs       = -1   # So you don't have to wait as long\n",
    "# random_state = 42   # For valid comparison with Assignment 1 \n",
    "\n",
    "# Also: time your model, use beepy, and end with displaying the accuracy score\n",
    "# on the test data: X_test_flat and y_test.  You already did this in Assignment 1,\n",
    "# and I also did all of that except the test data accuracy above.\n",
    "\n",
    "# 4 points for creating your classifier with the proper settings just described\n",
    "# and 1 point each for:\n",
    "#  capturing the start time\n",
    "#  fitting your model\n",
    "#  capturing the stop time\n",
    "#  printing a timing message\n",
    "#  calling beepy\n",
    "#  displaying the model's score on the test data\n",
    "\n",
    "#################### Insert your code below for 10 points ##################\n",
    "\n",
    "sgdBest = SGDClassifier(max_iter=1000, n_jobs=-1, random_state=42) \n",
    "BestParams    = {'loss':    ['modified_huber'], \n",
    "              'penalty': ['l2'],\n",
    "              'alpha':   [0.1]\n",
    "             } \n",
    "best_grid_search = GridSearchCV(sgdBest, BestParams, cv=3)\n",
    "startTime        =                        time.perf_counter()                                                                                     # Capture the starting time                1 points\n",
    "best_grid_search.fit(X_test_flat, y_test)                                                                                                         # Train the model                          4 points\n",
    "stopTime         =                        time.perf_counter()                                                                                     # Capture the ending time                  1 points\n",
    "print(f'\\nElapsed Time Default:           {stopTime - startTime:0.0f} seconds')                                                                   # Display the elapsed time                 1 points\n",
    "bp.beep(sound='ping')                                                                                                                             # Invoking favorite beepy sound.\n",
    "print('Default Model Accuracy: ',         best_grid_search.score(X_test_flat, y_test))                                                            # Accuracy of predictions on the test data 3 points\n",
    "  \n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# How did your model do?  When I did this, the accuracy was more than \n",
    "# 7 percentage points better than the baseline SGD model from assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61c0e9a-8d9a-4cf4-ac84-336dda7544d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed Time Default:           27 seconds\n",
      "Default Model Accuracy:  0.3998\n",
      "\n",
      "Elapsed Time Default:           22 seconds\n",
      "Default Model Accuracy:  0.3857\n"
     ]
    }
   ],
   "source": [
    "# Task 6: 10 points \n",
    "\n",
    "# Given the grid search results, the best L2 parameter value for alpha is 0.1, \n",
    "# (assuming you got the same results as I did)\n",
    "# but that was the highest value attempted in the grid search.\n",
    "# Could an even higher value of alpha do even better?\n",
    "# Let's try out 0.2 manually to find out. Keep everything else the same as the previous cell.\n",
    "# This relates to Geron's \"Tip\" box in the \"Grid Search\" section.\n",
    "# Make sure you print out the score on the test data to see the results\n",
    "\n",
    "#################### Insert your code below for 5 points ##################\n",
    "\n",
    "anotherSGD = SGDClassifier(max_iter=1000, n_jobs=-1, random_state=42) \n",
    "BestParams    = {'loss':    ['modified_huber'], \n",
    "              'penalty': ['l2'],\n",
    "              'alpha':   [0.2]\n",
    "             } \n",
    "anotherGridSearch = GridSearchCV(anotherSGD, BestParams, cv=3)\n",
    "startTime        =                        time.perf_counter()                                                         # Capture the starting time                1 points\n",
    "anotherGridSearch.fit(X_train_flat, y_train)                                                                          # Train the model                          4 points\n",
    "stopTime         =                        time.perf_counter()                                                         # Capture the ending time                  1 points\n",
    "print(f'\\nElapsed Time Default:           {stopTime - startTime:0.0f} seconds')                                       # Display the elapsed time                 1 points\n",
    "print('Default Model Accuracy: ',         anotherGridSearch.score(X_test_flat, y_test))                               # Accuracy of predictions on the test data 3 points\n",
    "bp.beep(sound='success')  \n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# And now, let's do that AGAIN but trying alpha set to 0.3\n",
    "\n",
    "#################### Insert your code below for 5 points ##################\n",
    "\n",
    "sgdFinal = SGDClassifier(max_iter=1000, n_jobs=-1, random_state=42) \n",
    "BestParams    = {'loss':    ['modified_huber'], \n",
    "              'penalty': ['l2'],\n",
    "              'alpha':   [0.3]\n",
    "             } \n",
    "FinalGridSearch = GridSearchCV(sgdFinal, BestParams, cv=3)\n",
    "startTime        =                        time.perf_counter()                                                         # Capture the starting time                1 points\n",
    "FinalGridSearch.fit(X_train_flat, y_train)                                                                            # Train the model                          4 points\n",
    "stopTime         =                        time.perf_counter()                                                         # Capture the ending time                  1 points\n",
    "print(f'\\nElapsed Time Default:           {stopTime - startTime:0.0f} seconds')                                       # Display the elapsed time                 1 points\n",
    "print('Default Model Accuracy: ',         FinalGridSearch.score(X_test_flat, y_test))                                 # Accuracy of predictions on the test data 3 points\n",
    "bp.beep(sound='success')  \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# alpha=0.2 did slightly better on my computer giving a score of: 0.3999 \n",
    "# But alpha=0.3 did not do as well.\n",
    "\n",
    "# So there are THREE lessons here:\n",
    "# 1. Grid search helps to systematically find better hyperparameters than the defaults.\n",
    "# 2. If your best hyperparameters are 'edge' values, i.e. either the largest or the smallest \n",
    "#    in the range of those tested, you may still be able to find a better value if you extend\n",
    "#    the range, as shown with the models in this cell.  \n",
    "# 3. To possibly do even better you should do another grid search\n",
    "#    with more values slightly below and above the best value found so far.\n",
    "\n",
    "# Another thing is that we only tested two loss functions.  But if you look \n",
    "# at the sklearn documentation for SGDClassifier, there are more than 2\n",
    "# so we would probably want to try them too, unless the documentation suggests\n",
    "# that they may not be worthwhile, e.g. some are designed for regression whereas\n",
    "# we are doing classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94c0f62-d987-4c1d-9b4f-34910a699dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed Time Default:           179 seconds\n",
      "Default Model Accuracy:  0.3857\n",
      "Best params:\t {'alpha': 0.3}\n",
      "Best estimator:\t SGDClassifier(alpha=0.3, loss='modified_huber', n_jobs=-1, random_state=42)\n",
      "0.2841395494183 {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.2648593505988995 {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.2828597322209322 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.30557922262891596 {'alpha': 0.0001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.24434034540238034 {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.31201945623874033 {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.2833798058228203 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.28163976862068424 {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.10207998888144161 {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.33569938945634864 {'alpha': 0.01, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.3073798922437488 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.3275393906498445 {'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "0.0999799996799776 {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "0.3301795046542367 {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "0.1000200000800176 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "0.3748599178982459 {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Task 7: 20 points\n",
    "\n",
    "# Set up a NEW grid search around the current best known value for alpha.\n",
    "# (If your best known value is different from mine, that's fine.  Use yours.)\n",
    "# Try 2 values less than your best alpha value, then 2 more values\n",
    "# that are more than the best value (you may skip the best value\n",
    "# since you already did it above).\n",
    "\n",
    "# NOTE: You are only creating a grid for 'alpha'.  Don't include any \n",
    "#       other hyperparameters in that grid, but make sure you fix\n",
    "#       all others with their values from your best model so far.\n",
    "\n",
    "# Supply ALL code, including, for 2 points each:\n",
    "# the new hp_grid\n",
    "# the new SGDClassifier for variable sgd, including the same values you just used above for\n",
    "#     loss, max_iter, n_jobs, and random_state\n",
    "# the new gridSearch \n",
    "# the timing start\n",
    "# the call to fit gridSearch\n",
    "# the timing stop\n",
    "# printing of the elapsed time\n",
    "# printing of the best_params_ \n",
    "# printing of the best_estimator_\n",
    "# the call to beepy\n",
    "\n",
    "#################### Insert your code below for 20 points ##################\n",
    "hp_grid    = {                                                                                                             # the new hp_grid\n",
    "              'alpha':   [ 0.3, 0.2, 0.01,0.001]                                                                           # Using 2 values above alpha and two values below.\n",
    "             } \n",
    "\n",
    "sgd = SGDClassifier(loss=\"modified_huber\", penalty='l2', max_iter=1000, n_jobs=-1, random_state=42) \n",
    "GridSearch = GridSearchCV(sgd, hp_grid, cv=3)\n",
    "startTime        =                        time.perf_counter()                                                              # Capture the starting time                1 points\n",
    "GridSearch.fit(X_train_flat, y_train)                                                                                      # Train the model                          4 points\n",
    "stopTime         =                        time.perf_counter()                                                              # Capture the ending time                  1 points\n",
    "print(f'\\nElapsed Time Default:           {stopTime - startTime:0.0f} seconds')                                            # Display the elapsed time                 1 points\n",
    "print('Default Model Accuracy: ',         GridSearch.score(X_test_flat, y_test))                                           # Accuracy of predictions on the test data 3 points\n",
    "print('Best params:\\t', GridSearch.best_params_)                                                                           # Let's look at the best hyperparameter values.\n",
    "print('Best estimator:\\t', GridSearch.best_estimator_)                                                                     # You can get additional info this way, \n",
    "bp.beep(sound='wilhelm')\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# The next code is copied from above so you can easily find the best model.\n",
    "# but you'll need to manually compare the best in this run to your previous best \n",
    "# to see which one is overall the best.\n",
    "\n",
    "gridResults = gridSearch.cv_results_\n",
    "for test_score, params in zip(gridResults[\"mean_test_score\"], gridResults[\"params\"]):\n",
    "    print(test_score, params)\n",
    "\n",
    "# For me, the best model was still alpha = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e3d7a-ccc7-463a-ae45-584a89d3dca3",
   "metadata": {},
   "source": [
    "### Optional Task 8: 10 extra credit points\n",
    "\n",
    "Above we performed cross validation during grid search via the GridSearchCV class.\n",
    "However, we can run cross validation directly on a model to get a good estimate of its performance.  You can do this by using cross_val_score. First, you will need to consult the documentation here to perform this task:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a60e637-5a05-464a-af8c-1c841f1f1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation scores: [0.33431331 0.33081338 0.33389332 0.33207336 0.31611368 0.33739325\n",
      " 0.33141977]\n",
      "Mean cross-validation scores: 0.33086001119518355\n",
      "Standard deviation of cross-validation scores: 0.006358925985668936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "# You have already trained a model called sgdFinal above for Task 6, \n",
    "# so you do not need to re-train it here unless you have restarted Anaconda\n",
    "# or rebooted your computer. If you have done one of those, then you need to \n",
    "# re-run task 6 so you can use sgdFinal here.\n",
    "\n",
    "# REMINDER: You'll need to consult the documentation to determine \n",
    "# the positions and/or names of the arguments.\n",
    "\n",
    "# Here are the possible points for the arguments to cross_val_score:\n",
    "# 1 point:  your pre-trained model sgdFinal from above\n",
    "# 1 point:  X_train_flat \n",
    "# 1 point:  y_train\n",
    "# 1 point:  Use 7-fold cross validation\n",
    "# 1 point:  Use all available processors (cores) to speed up training as we have previously done\n",
    "# 1 point:  Verbosity is turned off by default.  Turn it on by setting it either to 1 or to True\n",
    "#           This will print useful output, including the elapsed time\n",
    "# 1 point:  Use 'accuracy' for scoring\n",
    "# 1 point:  Print the vector of cross validation scores, i.e. the value of xValScores. \n",
    "#           Be sure to print some appropriate label to show what we are looking at.\n",
    "# 1 point:  Print the mean of xValScores (just use the mean() method)\n",
    "#           Be sure to print some appropriate label to show what we are looking at.\n",
    "# 1 point:  Print the standard deviation of xValScores (the std() method)\n",
    "#           Be sure to print some appropriate label to show what we are looking at.\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#################### Insert your code below for 20 points ##################\n",
    "crossvalscore = cross_val_score(sgdFinal, X_train_flat, y_train, cv=7, n_jobs = -1,verbose=True,scoring='accuracy')     #Creating an instance of the cross value score.\n",
    "print(\"The cross validation scores: \"+str(crossvalscore))                                                               #Printing out the mean of the cross validation scores.\n",
    "\n",
    "print(\"Mean cross-validation scores: \" + str(crossvalscore.mean()))                                                     #Printing out the mean of the cross validation scores.\n",
    "\n",
    "print(\"Standard deviation of cross-validation scores: \" + str(crossvalscore.std()))                                     #Printing out the standard deviation of the cross validation scores.\n",
    "# gridSearch =     GridSearchCV(sgd, hp_grid, cv=3)\n",
    "# new_cross_val_score = cross_val_score(sgdFinal, X_train_flat,y_train, cv=7)\n",
    "# pd.DataFrame(new_cross_val_score.cv_results_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b6b46-cd89-43ba-8686-eeda9708526a",
   "metadata": {},
   "source": [
    "### You are done!\n",
    "Your best model should be approximately 40% accurate on the test data.  That is not very good, but it's still about 4 times better than guessing at random.  In future assignments you will see that we can do much better than 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5566e9a-e3ad-4eb0-b4a3-6f0200f4c465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
