{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bad47f1-c15b-4b32-b38c-7c6ecd11d9c5",
   "metadata": {},
   "source": [
    "# Assignment 3: 75 points (+ 25 extra credit)\n",
    "## Exploratory Analysis with Yellowbrick, Confusion Matrix\n",
    "\n",
    "### IMPORTANT: \n",
    "#### You MUST read everything in this notebook CAREFULLY, including ALL code comments.  If you do not, then you may easily make mistakes.\n",
    "\n",
    "This week we will use a Python package called 'yellowbrick', which has some very pleasing data visualizations.  You will need to install the package in order for Task 1 to work properly.  Be sure to review the class slides if you need to. (But read the comments in the next cell first.)\n",
    "\n",
    "You may need to consult the following documentation URLs in order to complete this assignment:\n",
    "\n",
    "https://pypi.org/project/yellowbrick/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283e870-883a-43a0-8d7a-3f212ef58aca",
   "metadata": {},
   "source": [
    "### Important note:\n",
    "\n",
    "The original version of this notebook used a package called 'beepy', but that package will not work if you are using a Python version higher than 3.7.  Thus, the notebook was updated to use a package called 'playsound'.  You must do the following before running the next code cell:\n",
    "\n",
    "1. In your anaconda environment that you created for this class, open up a terminal window and run the command: pip3 install PyObjC\n",
    "\n",
    "\n",
    "2. AFTER you do that, then run: pip3 install playsound\n",
    "\n",
    "The reason for pyObjC is because playsound needs it for efficiency. If you install playsound before installilng PyObjC you will get an error when you try to use playsound, so do it in the order shown above\n",
    "\n",
    "4. Optional: If you want to use your OWN sound file instead of yourcodeisdonerunning.m4a that is fine, but you'll need to record it yourself and make sure that the 'playsound' function refers to it properly with whatever file name you use for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8f06b2-6156-41b5-aaa1-52958fc350e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1: 5 points.  Set up environment\n",
    "\n",
    "# If some of these do not import properly, you may need to install them and re-run\n",
    "# For example, the yellowbrick package is available in Anaconda, \n",
    "# but it's not installed by default. So either install it into your environment \n",
    "# using Navigator's UI, or use a terminal to install it with 'pip3 install yellowbrick' \n",
    "\n",
    "import keras\n",
    "import playsound\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "import matplotlib         as mpl   # for graphing\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy              as np    # for fast vector and matrix operations\n",
    "import pandas             as pd\n",
    "\n",
    "from keras.datasets          import cifar10  # The Keras package comes with several datasets, incl. CIFAR10\n",
    "from playsound               import playsound\n",
    "from pprint                  import pprint   # pprint means 'pretty print'.  You'll see why when we use it.\n",
    "from sklearn.linear_model    import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics         import confusion_matrix, precision_recall_curve, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from yellowbrick.classifier  import ClassBalance, ClassificationReport, ClassPredictionError, ConfusionMatrix, ROCAUC\n",
    "\n",
    "np.random.seed(42) # for reproducibility\n",
    "# The next line tells Jupyter to show all plots inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2470c9-21c3-4bd1-a14a-71db521d1b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2: 5 points\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset using the same variables\n",
    "# as in Assignment 2, including X_train, X_train_flat, y_train\n",
    "# as well as the corresponding variables for the test data.\n",
    "# Don't forget to include np.random.seed(42) in the beginning.\n",
    "# We defined and used LABEL_NAMES in Assignment 1, but did not use\n",
    "# it in Assignment 2.  However, we will be using it again here,\n",
    "# so make sure you copy it from Assignment 1 and add it here.\n",
    "\n",
    "#################### Insert your code below for 5 points ###############\n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "'Done' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b60d3-b186-4faa-888d-93758e156fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show randomly selected pictures\n",
    "# There is no task for you to write in this cell, \n",
    "# but it would be useful for you to study the code.\n",
    "\n",
    "def pictureGrid(rows, cols, labels, picData, picLabels, picPreds=None, predProbs=None, predsFlag=False):\n",
    "    '''Show random picture grid with labels, optionally with predicted label and its prediction probability.'''\n",
    "    # rows:       integer number of rows of pictures to display in grid\n",
    "    # cols:       integer number of pictures per row to display in grid\n",
    "    # labels:     list of picture labels\n",
    "    # picData:    matrix of pictures, one flattened picture vector per row\n",
    "    # picLabels:  ground truth of picture labels for picData\n",
    "    # picPreds:   predictions of picData from some model (predictions are integer indices of labels)\n",
    "    # predProbs:  corresponding probabilities of the predictions\n",
    "    # predsFlag:  boolean to indicate if predictions are included in function call\n",
    "    \n",
    "    figure = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            randomIndex = np.random.randint(0, len(picLabels))    # get index of random pic \n",
    "            ax = figure.add_subplot(rows, cols, c * rows + r + 1) # set up picture grid for display\n",
    "            ax.grid('off')\n",
    "            ax.axis('off')\n",
    "            ax.imshow(picData[randomIndex].reshape(32, 32, 3))    # convert flattened pic back to shape (32, 32, 3)\n",
    "            if predsFlag:\n",
    "                picLabel  = labels[picPreds[randomIndex]]         # get predicted label of test pic\n",
    "                predProb  = predProbs[randomIndex]                # get probability of test pic prediction\n",
    "            gtLabel = labels[picLabels[randomIndex]]              # ground truth label\n",
    "            if predsFlag:\n",
    "                ax.set_title(\"image: {}\\npred: {}\\nprob: {:.3}\\ngt: {}\".format(randomIndex, picLabel, predProb, gtLabel))\n",
    "            else:\n",
    "                ax.set_title(\"image: {}\\ngt: {}\".format(randomIndex, gtLabel))\n",
    "    plt.show()\n",
    "    \n",
    "pictureGrid(4, 5, LABEL_NAMES, X_test_flat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ea5e6-5102-462d-aaf5-da79bd0a819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: 10 points\n",
    "\n",
    "# Build another SGD Classifier using a different loss function.\n",
    "\n",
    "# We have already used SGDClassifier in the previous assignments.\n",
    "# By default, it uses parameter: loss='hinge' but in \n",
    "# Assignment 2 we discovered that modified_huber gave us better\n",
    "# results.\n",
    "\n",
    "# Another difference is that if we want to access the confidence scores \n",
    "# of our models, they are not available with hinge loss. \n",
    "# They are available with 'modified_huber' as our loss function. \n",
    "\n",
    "# The confidence scores will tell you how confident the ML algorithm is\n",
    "# for each of categories.  We will see this in the next cell.\n",
    "\n",
    "# You can keep the default values for all other arguments, i.e. you\n",
    "# won't need to mention any of the others.\n",
    "\n",
    "# Add your code below to do the following: (2 points each)\n",
    "# You can look at Assignment 2 to refresh your memory for \n",
    "# much of this.\n",
    "# 1. create an SGDClassifier using a modified_huber loss\n",
    "#    function, a random state of 42, and use all cores so\n",
    "#    you don't have to wait too long for this to train.\n",
    "# 2. Fit your model on the flattened training data with ground truth labels\n",
    "# 3. Add the code to capture timing and print the elapsed time, as before.\n",
    "# 4. Print the score (accuracy) of the trained model on the test data.\n",
    "#    You have already done that in Assignment 1, so go find it if\n",
    "#    you do not remember.  Add some text in your print statement\n",
    "#    so we know what we are looking at.\n",
    "# 5. Notify yourself when this is done with playsound: e.g. \n",
    "#    just insert the code: playsound('yourcodeisdonerunning.m4a')\n",
    "\n",
    "#################### Insert your code below for 10 points,  ###############\n",
    "####################    distributed as described above      ###############\n",
    "# Use the variables shown here, but there are additional lines of \n",
    "# code that you'll have to add.\n",
    "startTime  = \n",
    "\n",
    "sgdModHub  = \n",
    "                          \n",
    "\n",
    "\n",
    "stopTime   =                                   \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# In Assignment 2 we were able to get close to 40%\n",
    "# accuracy, but with this model you will see something \n",
    "# significantly worse than that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468272ff-f7ec-485c-a49d-92f1e0aae23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: 20 points\n",
    "\n",
    "# We used modified_huber to have access to the confidence values of the predictions.\n",
    "# Here is where we obtain those values using the predict_proba() method.\n",
    "# Not all models will provide this method (e.g. LinearSVC ), but many do.  \n",
    "# Knowing that predict_proba is a method should be enough information for you\n",
    "# to use it correctly, but you can consult the web or the documentation\n",
    "# for SGDClassifier on sklearn for more info.\n",
    "\n",
    "testImage = 7916\n",
    "\n",
    "# 5 points: Get the probabilities of all classes for every test image\n",
    "# 5 points: Then print those probabilities for the testImage\n",
    "\n",
    "#################### Insert your code below for 10 points,  ###############\n",
    "\n",
    "testProbs = \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# The highest value of these prediction probabilities for a given image corresponds \n",
    "# to the class that the model is most confident about.                                    \n",
    "# So let's get the index of the maximum value from that test image's prediction probabilities\n",
    "testImageProbs        = testProbs[testImage]              # Prediction probabilities for our testImage\n",
    "testImageMaxProbIndex = testImageProbs.argmax()           # Index of the max value from that array of 10 probabilities\n",
    "print('\\nIndex of predicted class:', testImageMaxProbIndex) # This should print a 4\n",
    "\n",
    "\n",
    "# The 5th array element is the one with index 4 since Python uses 0-based array indexing.  \n",
    "\n",
    "predictedClass = LABEL_NAMES[testImageMaxProbIndex]\n",
    "print('\\nPredicted class is: ' + predictedClass)      # This should print 'deer'  \n",
    "\n",
    "# You should see output where the 5th element of the array has the highest value, about 0.55.\n",
    "# Since the 5th element of LABEL_NAMES is 'deer', you should be looking at a picture\n",
    "# of a deer after you run this cell.  You should also see in the probability values\n",
    "# from the print statement that there is only one other class that has\n",
    "# a non-zero probability and that class is 'frog'.  So the classifier\n",
    "# is a little bit more confident about the picture being a deer than it is a frog.\n",
    "\n",
    "print('Low resolution picture (hopefully) of a ', predictedClass)\n",
    "\n",
    "# Let's view that picture to see if our model got the correct prediction\n",
    "\n",
    "# Use matplotlib's pyplot to show the picture of testImage.\n",
    "# Go up and look how you imported pyplot so you reference it correctly here.\n",
    "\n",
    "# Also, remember that testImage is just an index into the matrix X_test_flat\n",
    "#    If you take a look at Assignment 1, you'll find that I gave \n",
    "#    you almost the exact code that you'll need to use here.\n",
    "      \n",
    "# You will need to use 4 pyplot operations: (see Assignment 1!!!)\n",
    "#    a. 2 points: Use pyplot's 'figure' to set a figure size of 2 by 2\n",
    "#    b. 4 points: Use pyplot's 'imshow' to display the test image.\n",
    "#       Make sure that you reference X_test_flat to get this image!\n",
    "#       If you reference X_test I will not give you the 4 points.\n",
    "#       But you need to recall from Assignment 1 that when you flattened\n",
    "#       the images I told you in a comment:\n",
    "#       'Note: If you want to show the images again after flattening them,'\n",
    "#       'you'll have to reshape them back to their original (32, 32, 3)   '\n",
    "#    c. 2 points: Turn the pyplot axis 'off'\n",
    "#    d. 2 points: Call pyplot's 'show' to finally print the image into the notebook.\n",
    "\n",
    "#################### Insert your code below for 10 points   ###############\n",
    "\n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# If you used random_state=42 in your SGD classifier above\n",
    "# AND if the model's prediction is correct, then\n",
    "# that picture should be a deer.\n",
    "\n",
    "# If you try the above code with 'testImage = 4700' instead of 7916, \n",
    "# you will see a different picture, and the model's prediction should be wrong,\n",
    "# so you'll see a different predictedClass.  Try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-heading",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 5: 10 points\n",
    "\n",
    "# This cell assumes: \n",
    "# from yellowbrick.classifier import ClassBalance\n",
    "\n",
    "# We will use several tools from the yellowbrick package.  \n",
    "# In addition to the URL at the beginning of this notebook\n",
    "# you can read about yellowbrick here:\n",
    "# https://www.scikit-yb.org/en/latest/\n",
    "\n",
    "# And here is where you can see the details of ClassBalance for this cell:\n",
    "# https://www.scikit-yb.org/en/latest/api/target/class_balance.html \n",
    "\n",
    "# The tool ClassBalance shows how the data is distributed.\n",
    "# e.g. Is 90% of the data in only one category or evenly distributed?\n",
    "# Your analysis may differ depending on the answer to such questions.\n",
    "# For example, in Chapter 2 see Géron's discussion of stratified sampling.\n",
    "# If you remember the description of the CIFAR-10 dataset the chart\n",
    "# created should not be a surprise to you.\n",
    "\n",
    "# So let's look at class balance for the training data.\n",
    "\n",
    "# Create a class balance chart.  \n",
    "# 1. 6 points: Show the class balance of the training data. Show the names \n",
    "#    e.g. cat, ship, etc as bar labels. Give the chart a custom size. \n",
    "#    of 640 by 480 pixels by using the keyword argument: size=(640, 480)\n",
    "#    You can just use the default bar colors, and show \n",
    "#    either the default chart title OR, if you wish, you can give it\n",
    "#    your own custom title using the keyword 'title'.\n",
    "#    Save your ClassBalance description into the variable cifar10Balance\n",
    "# 2. 2 points: Call the fit method on cifar10Balance, passing it y_train\n",
    "# 3. 2 points: Call the show method on cifar10Balance\n",
    "\n",
    "########################### Your code starts here: 10 points ###########################\n",
    "\n",
    "# Show the first chart below this line, approx. 3 lines of code:\n",
    "cifar10Balance = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## Your code ends here ################################\n",
    "\n",
    "# In the plots you will see 'support' as the y-axis label.  \n",
    "# The term 'support' in this chart refers to the number of data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a93d9-e527-4e7f-bfa9-80bc88a162ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: 10 points\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "\n",
    "# You can view a basic confusion matrix by passing the ground truth and \n",
    "# the corresponding predictions of your model as the two arguments \n",
    "# to sklearn's confusion_matrix function.\n",
    "\n",
    "# 1. 4 points: To do this, first call the predict method of your \n",
    "#    sgdModHub passing X_test_flat as the method's argument.\n",
    "#    Convert the results to an np.array and save that value into\n",
    "#    the variable modelPredictions.\n",
    "# 2. 4 points: Call confusion_matrix, passing it the ground truth  \n",
    "#    labels y_test and those modelPredictions as two arguments, and  \n",
    "#    save the confusion matrix into the variable confMat\n",
    "# 3. 2 points: Display the value of confMat as the output of the cell.\n",
    "\n",
    "#################### Insert your code below for 10 points   ###############\n",
    "\n",
    "modelPredictions = \n",
    "confMat          = \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# We can see in the main diagonal that the correct class is OFTEN smaller than \n",
    "# one or more of the others, which is really not a surprise, given that\n",
    "# sgdModHub is not a very good predictor of the images.\n",
    "\n",
    "# Also notice that, while sklearn's confusion_matrix is easy to use, it's bad \n",
    "# because it does not tell you if the ground truth values are displayed\n",
    "# on the rows or on the columns.  \n",
    "\n",
    "# Fortunately, there are much better ways to view confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58834af1-5df9-4860-bd91-636ff0433c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yellowbrick's Confusion Matrix (with Heat Map!)\n",
    "\n",
    "# The yellowbrick package makes visualizating model statistics \n",
    "# much easier (and better!) than using standard sklearn tools. \n",
    "# You can learn more about yellowbrick at: https://www.scikit-yb.org/en/latest/index.html \n",
    "# Yellowbrick uses Matplotlib \"under the covers\" to create the plots.\n",
    "\n",
    "cmTrainedModel = ConfusionMatrix(sgdModHub, \n",
    "                                 classes=LABEL_NAMES, \n",
    "                                 size   =(640, 480))   \n",
    "                                 # The size of the plot in pixels.\n",
    "                                 # Omit it for the smaller default size\n",
    "\n",
    "# To create the ConfusionMatrix, we need to make some predictions on the test data.\n",
    "# The score method runs predict() on the data, calculates the accuracy score,\n",
    "# and then creates the confusion_matrix from scikit-learn.\n",
    "print('\\nAccuracy of cmTrainedModel model on test data:',\n",
    "      cmTrainedModel.score(X_test_flat, y_test), '\\n')\n",
    "\n",
    "cmTrainedModel.show() # Call the 'show' method to display that confusion matrix\n",
    "\n",
    "# Check it out now! Notice how much more informative this is.\n",
    "# The heat map shows darker colored cells for higher numbers \n",
    "# of pictures assigned to the categories of the labels in the columns.  \n",
    "# And now you can see the rows clearly labeled as ground truth, \n",
    "# while the columns are clearly labeled as the predictions.\n",
    "\n",
    "# At a glance, you can see from the colors that sgdModHub is a bad classifier.\n",
    "# It seems like almost everything looks like a deer to sgdModHub!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c0d4b-0d88-46ef-b363-33108a944747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 7: 15 points\n",
    "\n",
    "# Now we begin with a model that is not yet trained.\n",
    "\n",
    "# Using the previous cell as a guide, add your code to do the following:\n",
    "# 1. 5 points: Create a new SGDClassifier that again uses modified_huber\n",
    "#    but now set the alpha argument to 0.2, which will greatly\n",
    "#    improve the accuracy.  Set n_jobs if you want to speed up training\n",
    "#    and use a random state of 42.\n",
    "#    Save this untrained classifier into variable sgdUntrained\n",
    "# 2. 5 points: call ConfusionMatrix, passing your \n",
    "#    untrained model sgdUntrained as the first argument.\n",
    "#    Other arguments should be the label names for classes,\n",
    "#    a size of 720 by 540 pixels for your confusion matrix,\n",
    "#    and a custom title (just set keyword 'title' to a string \n",
    "#    that you think is appropriate for this task.)\n",
    "#    Save the confusion matrix object into variable cmBetter\n",
    "# 3. 3 points: Call the fit method on cmBetter to train your model\n",
    "#    on the training data.\n",
    "# 4. 1 point: print an approprite message along with the accuracy\n",
    "#    score on the test data\n",
    "# 5. 1 point: call the show method on cmBetter\n",
    "\n",
    "\n",
    "#################### Insert your code below for 15 points   ###############\n",
    "\n",
    "sgdUntrained = \n",
    "\n",
    "\n",
    "cmBetter    = \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "print('\\n Class counts of the test data:', cmBetter.class_counts_) \n",
    "# If you try this with the pretrained model in the previous cell you'd get an error,                                                                    \n",
    "# which is what the warning message of the previous cell was all about.\n",
    "\n",
    "# If you did this correctly, then \n",
    "# you can see quickly that the darker colors are along the main diagonal, \n",
    "# which is what we want for a good classifier -- the darker the better.\n",
    "# You can see that the predictions for 'bird' are not as good as the other \n",
    "# categories since the 'bird' cell on the main diagonal is lighter \n",
    "# in color than the others on that diagonal, and the best predictions \n",
    "# are for 'airplane', 'ship' and 'truck' because they are the darkest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e6533-9c7d-412b-907b-d02b510e3ed4",
   "metadata": {},
   "source": [
    "### Extra Credit: 25 points total divided between Two Tasks of 15 and 10 points, respectively.\n",
    "\n",
    "If you wish to do this task, you will combine what we learned above with grid search and 3-fold cross validation that we did in Assignment 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97f58d-fe65-44e8-a5da-2971185a42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task 8: 15 extra credit points\n",
    "\n",
    "# For this you will create a totally different model using an algorithm\n",
    "# called LogisticRegression.  Even though it's called regression,\n",
    "# it can be used as a classifier.  You have already imported it\n",
    "# in the first cell above.  The first thing to do is call\n",
    "# LogisticRegression with 2 arguments: n_jobs=-1 and a random\n",
    "# state of 42.  You can use the default values for everything else.\n",
    "# Save the value of that model in the variable logReg\n",
    "\n",
    "# LogisticRegression runs a LOT more slowly than SGDClassifier \n",
    "# for multi-class classification (you'll understand why when we study it \n",
    "# soon in class), so we will only do grid search on ONE hyperparameter \n",
    "# and we will only test 3 values. Just like SGDClassifier uses L2\n",
    "# regularizaation, so does LogisticRegression, but in LogisticRegression\n",
    "# the hyperparameter that controls the regularization is called 'C'.\n",
    "# Thus, we will create a grid called 'C_grid' using 'C' as the key\n",
    "# and a list of values to try for C during cross validation.  Since\n",
    "# LogisticRegression is so slow, we will only test 3 values:\n",
    "# [0.5, 1.0, 1.5]  Use that list as the value for key C in C_grid.\n",
    "# The value 1.0 is the default value, so we will see if 0.5 or 1.5\n",
    "# might work a little better when compared to 1.0\n",
    "\n",
    "# You can expect this to take, as I said, a LOT longer than SGDClassifier\n",
    "# even with only 3 values being tried out for cross-validation.  To save\n",
    "# some more time, set the cross validation to do only 3-fold.  If you\n",
    "# don't set it, the default value is to do 5-fold cross validation and \n",
    "# you will be waiting even longer! On my computer it took almost 20 minutes \n",
    "# for just 3 folds, so be prepared to wait for it!\n",
    "\n",
    "# Capture your start and end times, print out the elapsed time and use \n",
    "# playsound to alert yourself when training is done.\n",
    "\n",
    "# Also, print out your grid's best_estimator_\n",
    "# After you see these results, continue on to the next cell.\n",
    "\n",
    "# NOTE: You will probably see numerous warning messsages in the output,\n",
    "# but they are not errors and you can ignore them. HOWEVER, if you DO\n",
    "# see an actual error message then you did something wrong that you\n",
    "# will have to fix!\n",
    "\n",
    "#################### Insert your code below for 15 points ##################\n",
    "\n",
    "C_grid      = \n",
    "                                                     \n",
    "logReg      = \n",
    "gridSearch  = \n",
    "\n",
    "startTime   = \n",
    "\n",
    "\n",
    "stopTime    = time.perf_counter()                             # Capture the ending time\n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf5b33-6596-4c0e-8e7a-5cf287f66bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task 9: 10 Extra credit points\n",
    "\n",
    "# Now that you know which combination of values gives you the best estimator,\n",
    "# REDEFINE the logReg variable using those best values from the printout.  \n",
    "# Now, set it up in the same way as you did above to create \n",
    "# a confusion matrix, and call its fit method on the training data. \n",
    "# Then, evaluate the trained model on the test data,  \n",
    "# show the confusion matrix, and print the accuracy score to see \n",
    "# how it compares with the previous models you have trained. \n",
    "\n",
    "#################### Insert your code below for 15 points ##################\n",
    "\n",
    "logReg    = \n",
    "\n",
    "\n",
    "########################### Your code ends above ###########################\n",
    "\n",
    "# This may show a bit better accuracy score than what you have seen previously\n",
    "# If you compare this confusion matrix with the previous one, you'll see that\n",
    "# there are a lot more correct predictions for 'bird', hence the improvement\n",
    "# in overall accuracy.  Others do better too, but ship and truck are slightly\n",
    "# worse when I trained this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
