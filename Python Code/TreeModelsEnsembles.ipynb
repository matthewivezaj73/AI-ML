{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bad47f1-c15b-4b32-b38c-7c6ecd11d9c5",
   "metadata": {},
   "source": [
    "# Assignment 5: 75 points (plus 10 points extra credit)\n",
    "## Decision Trees, Random Forest, Visualization of Predictions, and Ensembles\n",
    "\n",
    "### IMPORTANT: \n",
    "#### You MUST read everything in tnis notebook CAREFULLY, including ALL code comments.  If you do not, then you may easily make mistakes.\n",
    "\n",
    "This week we will build models based on decision trees.  You will need to consult some of the following in order to find out the names of model parameters for training:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "And we again use Yellowbrick, this time for the prediction visualizations :\n",
    "\n",
    "https://www.scikit-yb.org/en/latest/api/classifier/class_prediction_error.html \n",
    "\n",
    "Be sure to review the class slides if you need to. (But read the comments in this notebook first.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f06b2-6156-41b5-aaa1-52958fc350e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: 5 points.  Set up environment\n",
    "\n",
    "# If some of these do not import properly, you may need to install them and re-run\n",
    "\n",
    "import keras\n",
    "import sklearn\n",
    "import playsound\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "import matplotlib         as mpl   \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy              as np   \n",
    "import pandas             as pd\n",
    "\n",
    "from keras.datasets          import cifar10  \n",
    "from playsound               import playsound\n",
    "from pprint                  import pprint   \n",
    "\n",
    "from sklearn.ensemble        import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model    import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics         import confusion_matrix, precision_recall_curve, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import LinearSVC, SVC\n",
    "from sklearn.tree            import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from yellowbrick.classifier  import ClassBalance, ClassificationReport, ClassPredictionError, ConfusionMatrix\n",
    "\n",
    "np.random.seed(42) \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2470c9-21c3-4bd1-a14a-71db521d1b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is the code to load and prep the CIFAR-10 data\n",
    "\n",
    "np.random.seed(42) # Make this notebook's output stable across runs\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Normalize the data\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "X_train /= 255.0  # The largest number is 255, and the smallest 0\n",
    "X_test  /= 255.0  # So this division will normalize the data.\n",
    "\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0],   X_test.shape[1]*X_test.shape[2]*X_test.shape[3])\n",
    "\n",
    "# We also have to use ravel to change the target values (the values we want to predict). \n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "LABEL_NAMES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "'Done' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc21a76-a04a-4ee3-b9fa-36627265d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2, 5 Points\n",
    "\n",
    "# 2 points: Create a DecisionTreeClassifier model with 'random_state' of 42\n",
    "#           and a maximum depth of 9, setting its value to the variable decTree\n",
    "# 2 points: Call its fit method to train the model on X_train_flat, y_train\n",
    "# 1 point:  Print the accuracy score of decTree with an appropriate message \n",
    "\n",
    "# About 1 minute on my computer\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "decTree = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################  insert your code above ############################\n",
    "\n",
    "# You will probably see a score that is about 30%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-driving",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3: 5 Points\n",
    "\n",
    "# Visualizing the class prediction errors with Yellowbrick\n",
    "# The URL to the yellowbrick documentation is in cell 1 \n",
    "\n",
    "# 2 points: Set decTreeViz to the value of ClassPredictionError taking as\n",
    "#           arguments: the decTree defined in the previous cell, the\n",
    "#           classes set to LABEL_NAMES, and the size set to make a graph \n",
    "#           that is 640 by 480 pixels. Because decTree is already trained,\n",
    "#           tell the visualizer that is_fitted is True\n",
    "#           If you don't do that, you would have to re-train the model\n",
    "#           here, causing you to wait unnecessarily!\n",
    "# 1 point:  Call the score method on decTreeViz, passing it the test data\n",
    "#           in X_test_flat and y_test\n",
    "# 1 point:  Print the 'score_' property of decTreeViz (it's a property,\n",
    "#           not a method, so there are no parentheses and no arguments for it)\n",
    "#           In your print statement include some appropriate message so we\n",
    "#           know what we are looking at.\n",
    "# 1 point:  Call the show method of decTreeViz to display the graph just\n",
    "#           like you would do for matplotlib\n",
    "\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "decTreeViz = \n",
    "\n",
    "# If you don't tell ClassPredictionError that the model is already trained,\n",
    "# then you would have to execute the following line to train it again.\n",
    "# decTreeViz.fit(X_train_flat, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         \n",
    "\n",
    "##########################  insert your code above ##########################\n",
    "\n",
    "# You should see a warning message that would disappear if you trained the model\n",
    "# here as shown in the line of code that is commented out.\n",
    "\n",
    "# the bar colors are, bottom-up, in order of LABEL_NAMES, e.g. airplane on bottom, truck on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a17499-b2e5-4d3e-8520-067724aef49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decision tree model above limited the depth of the tree to only 9 levels\n",
    "# If you remove the maximum depth parameter, it will use the default\n",
    "# which is unlimited!  Let's see if it does better or worse than 9\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42) \n",
    "dt.fit(X_train_flat,  y_train)\n",
    "print('\\nThe test accuracy of 1 decision tree with unrestricted depth is:', dt.score(X_test_flat, y_test)) \n",
    "# Compares to 0.3041 with depth of 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98868ce-d942-4617-852c-f58377ffbdea",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### How do you explain that result?  \n",
    "One of the characteristics of decision trees is that they can easily overfit the training data, and that is what is happening here if we don't limit the depth of the tree.  When I had you build your first model using only 9 levels, I had previously done a grid search and found that 9 was better than 8, but accuracy started to decrease with deeper trees.\n",
    "\n",
    "So what can we do to get better results than a single decision tree?  The answer is that we introduce democracy by using an ensemble of trees and let them all vote on the predictions, as discussed in the text and my lectures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57581ef4-7762-4a3d-a8ce-7f5847a62374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 4, 5 Points\n",
    "\n",
    "# ENSEMBLE METHODS\n",
    "# Let's first build a random forest model to compare to the single decision tree.\n",
    "# We use max_depth=9 so we can compare it to the single decision tree \n",
    "# that used the same depth.\n",
    "\n",
    "# We will build an ensemble of 100 classification trees, which is the default \n",
    "# even if you do not reference n_estimators, which controls the number of trees.\n",
    "# If you change that to 500 decision trees you will only get about \n",
    "# an additional 0.5% improvement.\n",
    "\n",
    "# Our expectation is that the ensemble will perform better than one tree.\n",
    "# Since we are buildng 100 trees, we'll use n_jobs=-1 to speed up the computation, \n",
    "# building them in parallel.\n",
    "\n",
    "# 2 points: Build a RandomForestClassifier (see documentation URL in cell 1 above)\n",
    "#           Use a max depth of 9, all available CPU cores (n_jobs),\n",
    "#           random state of 42 and 100 estimators.\n",
    "#           We will also set verbose=True which will print progress\n",
    "#           information to the screen, which helps us know your computer\n",
    "#           is actually doing something useful.\n",
    "#           Save your model definition into variable rf\n",
    "# 1 point:  Fit rf on the training data.\n",
    "# 2 points: Print the accuracy score on the test data with an appropriate message.\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "rf = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################  insert your code above ##########################\n",
    "\n",
    "# This should be fast, but you may see messages created by verbose=True\n",
    "# even after your print statement shows your model's test accuracy.\n",
    "\n",
    "# On my computer this gave a score of 0.4126 vs. a single tree score about 10% points lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41294572-6f9d-47c7-9e8f-5b0cd1006b25",
   "metadata": {},
   "source": [
    "#### See how much better an ensemble is?\n",
    "You probably see about 10 percentage points higher accuracy with an ensemble of 100 trees.  If 100 gives us that big an improvement, how about seeing what 200 trees can do for us?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e2f76-fa93-41bf-928c-845df650e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf200 = RandomForestClassifier(max_depth=9,     n_jobs=-1, verbose=True,\n",
    "                               random_state=42, n_estimators=200)\n",
    "\n",
    "rf200.fit(X_train_flat,  y_train)\n",
    "\n",
    "print('\\nThe random forest ensemble with 200 trees and depth 9 has a test accuracy of:', \n",
    "      rf200.score(X_test_flat, y_test), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614e989-5682-4485-9ddc-2280c5d16c78",
   "metadata": {},
   "source": [
    "#### It seems that adding more democracy has only a small benefit, at least for random forest models at depth 9 on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633888ae-7903-484c-b4a4-9db0d05c86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: 5 points\n",
    "\n",
    "# Let's look at the class prediction visualizer for this model.  \n",
    "# Because it's only a little bit more accurate than the previous\n",
    "# model, you may not expect the graph to look much different.\n",
    "\n",
    "# If you had trouble with Task 3, then you will have trouble here.\n",
    "# If so, it's time to ask your instructor for help before you submit\n",
    "# this assigment.\n",
    "\n",
    "# The same point assignment as in Task 3 above for the 4 statements: \n",
    "#  define: 2\n",
    "#  score:  1\n",
    "#  print:  1 \n",
    "#  show:   1\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "rf200Viz = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################  insert your code above ##########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dec702-85b0-48dc-a2d0-746ea51be75c",
   "metadata": {},
   "source": [
    "#### Compare this graph to the previous one.  There is a major difference.\n",
    "Compare the height of the bars in this graph to the previous graph.  What do you notice?  See how much shorter the total height of the bars are here for birds and cats?  Even though the overal model has slightly better accuracy, there has been a major shift for these two categories, and it seems both birds and cats are now much harder to recognize than before.  Remember, each of the test data categories have 1000 actual observations, but rf200Viz only thinks it sees about 300 birds, and correctly predicts only 120.  There are also very few correct cat predictions.  So the lesson here is that the overall numeric accuracy does not give a complete picture.  You need to see more detail to know where to focus your improvements.  \n",
    "\n",
    "Where can we see more exact detail?  In a confusion matrix, of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e050e7d-627f-4a4d-907c-d984a1443e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: 5 points\n",
    "\n",
    "# You have already built a confusion matrix for assignment 3\n",
    "# so go back and remind yourself how to do it, OR read the\n",
    "# documentation for it in Yellowbrick here:\n",
    "# https://www.scikit-yb.org/en/latest/api/classifier/index.html\n",
    "\n",
    "# 2 points: Create a yellowbrick ConfusionMatrix, on rf200, with\n",
    "#           classes set to LABEL_NAMES, and a graph size of 640 by 480.\n",
    "# 2 points: Print the accuracy score of that rf200ConfMatrix on the\n",
    "#           test data with an appropriate message.\n",
    "# 1 point:  Show rf200ConfMatrix\n",
    "\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "rf200ConfMatrix = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################  insert your code above ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c33cfd-ab67-415d-948c-e43228a44c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 7: 5 points\n",
    "\n",
    "# Since the default of 100 trees works well and is also not slow, let's push it\n",
    "# and see how it does on 1000 trees, again with no restriction on the depth, but it will take \n",
    "# a lot more time to run, and your fan may run hard to cool down the CPU:\n",
    "\n",
    "# about 3 minutes on my computer\n",
    "\n",
    "# 2 points: Create a RandomForestClassifier, saving it to rfDeep, with\n",
    "#           no maximum depth, using maximum CPU cores, 1000 trees,\n",
    "#           a random state of 42 and verbose set to True.\n",
    "# 2 points: Fit the model to the training data\n",
    "# 1 point:  Print the accuracy score of that rfDeep on the\n",
    "#           test data with an appropriate message.\n",
    "\n",
    "####################  insert your code below for 5 points ####################\n",
    "\n",
    "rfDeep = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################  insert your code above ##########################\n",
    "\n",
    "# you should see that more trees certainly does have an added benefit at the expense of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e951c26-8eda-45d2-bfe0-e80da61a0968",
   "metadata": {},
   "source": [
    "#### By combining unlimited tree depth and a lot more trees, we get the most accurate model we have tried so far!\n",
    "But we still have a long way to go, as we are only getting correct predictions about half the time.  Let's look at our prediction visualizations again.\n",
    "\n",
    "Remember above when we created only one decision tree with an unlimited depth and it overfit the training data? Notice that with an ensemble of 1000 trees it does NOT overfit the data.  Our test accuracy improved instead of getting worse.  Why is that?  It's because of the ensemble.  Adding more models acts as a regularizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081c34b-cfb9-4e4a-a614-f38b1b90bb36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 8: 15 Points   \n",
    "\n",
    "# On my computer this takes less than 3 minutes.\n",
    "\n",
    "# Since this was our best model to date, let's graph once more\n",
    "# both the predictions graph and the confusion matrix, both\n",
    "# using the tools from Yellowbrick as before.\n",
    "\n",
    "# 1 point:  First, print the score of rfDeep again, with an appropriate message\n",
    "# 3 points: Add the code to create a ClassPredictionError object on rfDeep\n",
    "# 2 points: score it on the test data \n",
    "# 2 points: and show it\n",
    "\n",
    "# 3 points: Add the code to create a ConfusionMatrix object on rfDeep\n",
    "# 2 points: score it on the test data \n",
    "# 2 points: and show it\n",
    "\n",
    "# Remember that you are graphing the rfDeep model from the previous cell\n",
    "\n",
    "####################  insert your code below for 15 points ####################  \n",
    "\n",
    "# add your print statement\n",
    "\n",
    "# Build, score and show the ClassPredictionError for rfDeep\n",
    "rfDeepViz =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build, score and show the ConfusionMatrix for rfDeep\n",
    "rfDeepCM = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################  insert your code above ##########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a74e99-6a32-44da-bd0a-0c31db68dd07",
   "metadata": {},
   "source": [
    "#### Notice how much better the predictions are for both bird and cat with rfDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2a23f-4f6c-4030-ac8e-0dc2114286da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 9: 25 points\n",
    "\n",
    "# Heterogeneous Ensemble\n",
    "\n",
    "# Just as you can have an ensemble of identical model types (e.g. random\n",
    "# forest is an ensemble of decision trees), you can create an ensemble of\n",
    "# completely different modeling types, which we will construct here with\n",
    "# SGDClassifier, LogisticRegression and RandomForestClassifier\n",
    "\n",
    "# If need, you can consult:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# And here is the reference to manage the ensemble:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html \n",
    "\n",
    "# The ensemble will likely work better if each of the participating models \n",
    "# has a similar accuracy in isolation to each of the other models. I am giving\n",
    "# you various hyperoparameter values below to help achieve that goal.\n",
    "\n",
    "# Here are the point distributions: \n",
    "# 10 points total for defining the 3 classifiers (i.e. 3.33 points for each model)\n",
    "# 10 points for defining the ensemble using VotingClassifier\n",
    "# 10 points to create a for-loop that fits, trains, and evaluates each model,\n",
    "#           including the final ensemble (i.e. 4 models in total), \n",
    "#           and prints the resulting accuracy score of each.\n",
    "\n",
    "# EACH of the 3 classifiers should include a random state of 42 \n",
    "# and n_jobs set to the maximum number of cores.\n",
    "# You have already done both of these several times by now.\n",
    "\n",
    "# There are additional parameter suggestions for each of the 3 classifiers \n",
    "# in the comments below.\n",
    "\n",
    "####################  insert your code below for 25 points #################### \n",
    "startTime = time.perf_counter()  \n",
    "\n",
    "### 10 points for this subsection to define the 3 classifiers: \n",
    "\n",
    "# In addition to the random state and n_jobs mentioned above,\n",
    "# SGDClassifier should use alpha of 0.2 and a modified_huber loss function \n",
    "sgd      = \n",
    "\n",
    "\n",
    "# In addition to the random state and n_jobs mentioned above,\n",
    "# LogisticRegression should use a value of 1.5 for C (to regularize)\n",
    "logReg   = \n",
    "\n",
    "\n",
    "# In addition to the random state and n_jobs mentioned above,\n",
    "# RandomForestClassifier should use 200 trees and a maximum depth of only 9\n",
    "rndFor   = \n",
    "\n",
    "\n",
    "### 5 points for this subsection defining the VotingClassifier:\n",
    "\n",
    "# There will be a total of 3 keyword arguments for  VotingClassifier.\n",
    "# The first will tell VotingClassifier which estimators (models)\n",
    "# to use for the ensemble.  The value of that keyword should be a  \n",
    "# list of Python pairs.  The second element of each pair is just the\n",
    "# variable defined above for one of the model definitions,\n",
    "# and the first element of the same pair should be simply \n",
    "# the same variable in quotes.  For example, the very first\n",
    "# Python pair in this list should be: ('sgd', sgd).\n",
    "# Now you supply the other two pairs in the list.\n",
    "\n",
    "# The next keyword argument will tell VotingClassifier\n",
    "# to use all available cores so the computation will be faster,\n",
    "# and the last keyword will indicate that the ensemble \n",
    "# is to do 'hard' voting, as opposed to 'soft' voting. See text \n",
    "# and class lectures for what this means. One URL near the top \n",
    "# of this cell points to the documentation for VotingClassifier\n",
    "# so you can find the correct keyword argument names.\n",
    "\n",
    "ensemble = \n",
    "\n",
    "\n",
    "### 10 points for a loop to train, score and print the scores \n",
    "#           of the 3 individual classifiers as well as the ensemble itself.\n",
    "\n",
    "# In Assignment 1, Task 4 you used two variables in a for-loop\n",
    "# where the variables were bound by \n",
    "# two lists that were zipped together.  You will do that again here.\n",
    "# The first list contains references to the 4 models, \n",
    "# i.e. [ sgd,      logReg,    rndFor,   ensemble]\n",
    "# The second list contains the names of those 4 models as strings,\n",
    "# i.e. ['sgd',    'logReg',  'rndFor', 'Ensemble']\n",
    "# The loop variable called clf is for the first list and the\n",
    "# loop variable called label is for the second list.\n",
    "# Go back and LOOK at the for-loop in Task 4, Assignment 1 so\n",
    "# you don't waste time on this.  It should be quite easy.\n",
    "\n",
    "# In the body of the loop you will first call the fit method of clf, \n",
    "# passing it the training data.\n",
    "# Then you will call its score method passing it the test data, \n",
    "# and saving the result in the variable clf_score\n",
    "# This is followed by a print statement, which I have given to you.\n",
    "\n",
    "for clf, label in \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf_score = \n",
    "    print(\"Test Accuracy: %0.2f [%s]\" % (clf_score, label))\n",
    "    \n",
    "# This takes about 270 seconds (4.5 minutes) on my computer\n",
    "stopTime  = time.perf_counter() \n",
    "print(f'Elapsed time: {stopTime - startTime:0.4f} seconds')\n",
    "\n",
    "playsound('yourcodeisdonerunning.m4a')\n",
    "    \n",
    "###########################  insert your code above ##########################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8352596-02ee-46ad-836e-725c568b1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10:  10 extra credit points\n",
    "\n",
    "# Make a copy of the previous cell, and modify it to perform 'soft' instead of 'hard' voting.\n",
    "# Run that cell, and then look at its results.\n",
    "# At the bottom of that new cell put some comments that tell me, what values you see on YOUR\n",
    "# computer for:\n",
    "\n",
    "# 1. The accuracy scores for:\n",
    "#    (a) the SGD model, \n",
    "#    (b) the logistic regression model, and \n",
    "#    (c) the reandom forest model.\n",
    "#    You should see the same scores for these models in both the hard voting and the soft voting cells,\n",
    "#    so you only need to give these scores one time for me.\n",
    "\n",
    "# 2. The score of your hard voting ensemble.\n",
    "\n",
    "# 3. The score of your soft voting ensemble.\n",
    "\n",
    "# On my computer, the hard voting ensemble did slightly better than any of the 3 \n",
    "# individual models, and the soft voting ensemble did slightly better than the hard.\n",
    "# However, that does not mean you will get the same results, nor does it matter\n",
    "# for your grade.  I will run your code on my computer, as always.  The main thing\n",
    "# I'm looking for is that your code has no logic errors and does not crash.\n",
    "\n",
    "# That's it.  If you get the hard voting cell working properly, this will be \n",
    "# an EASY 10 points of extra credit for you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
