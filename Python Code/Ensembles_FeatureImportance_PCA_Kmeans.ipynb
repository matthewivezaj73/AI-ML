{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15781498-7cf6-4426-bb4d-b5c471c13829",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 6: 75 points + 5 points extra credit\n",
    "## More on Ensembles, Feature Importance, KMeans clustering, Dimensionality Reduction\n",
    "\n",
    "### IMPORTANT: \n",
    "#### You MUST read everything in tnis notebook CAREFULLY, including ALL code comments.  If you do not, then you may easily make mistakes.\n",
    "\n",
    "Yet again we will use Yellowbrick, for Silhouette Scoring on KMeans:\n",
    "\n",
    "Be sure to review the class slides if you need to. (But read the comments in this notebook first.)\n",
    "\n",
    "Some relevant documentation can be found for KMeans and the Silhouette Score visualizer at these 2 URLs:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "https://www.scikit-yb.org/en/latest/api/cluster/silhouette.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9ab79-03f6-47a0-a8a6-d719dbf81685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: 5 points.  Set up environment\n",
    "\n",
    "####################################################################################\n",
    "# If some of these do not import properly, you may need to install them and re-run #\n",
    "####################################################################################\n",
    "\n",
    "import keras\n",
    "import playsound\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import time\n",
    "    \n",
    "import matplotlib         as mpl   \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy              as np   \n",
    "import pandas             as pd\n",
    "\n",
    "from keras.datasets          import cifar10  \n",
    "from playsound               import playsound\n",
    "from pprint                  import pprint   \n",
    "\n",
    "from sklearn.cluster         import KMeans\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.ensemble        import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model    import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics         import confusion_matrix, precision_recall_curve, precision_score, recall_score, f1_score, silhouette_score, homogeneity_score, completeness_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import LinearSVC, SVC\n",
    "from sklearn.tree            import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from yellowbrick.classifier  import ClassBalance, ClassificationReport, ClassPredictionError, ConfusionMatrix\n",
    "from yellowbrick.cluster     import SilhouetteVisualizer\n",
    "\n",
    "np.random.seed(42) \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9d8fd-485a-4fba-9b59-165ddd7e776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I modified these function definitions from Géron's ch. 9 \n",
    "# notebook.  We will use them below to display  \n",
    "# a Voroni plot of KMeans clusters.\n",
    "\n",
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='r'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=5, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=3, linewidths=3,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=False, show_ylabels=False):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7db16-b0e3-4ae2-874c-0d48b8322720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is the code to load and prep the CIFAR-10 data\n",
    "\n",
    "np.random.seed(42) # Make this notebook's output stable across runs\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# Normalize the data\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "X_train /= 255.0  # The largest number is 255, and the smallest 0\n",
    "X_test  /= 255.0  # So this division will normalize the data.\n",
    "\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0],   X_test.shape[1]*X_test.shape[2]*X_test.shape[3])\n",
    "\n",
    "# We also have to use ravel to change the target values (the values we want to predict). \n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "LABEL_NAMES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "'Done' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1b034-4c67-41de-8569-bc46874a91f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Now let's consider a bagging model, which is very similar to a random forest model, but not identical.\n",
    "\n",
    "The primary difference is that, for each time a tree node is split into a branch, a bagging model chooses the best feature from among ALL of the features, whereas a random forest model only chooses from a subset of all features. By default the random forest will take a random sample of the square root of the number of features, and find the best feature from that subset.   \n",
    "\n",
    "This difference has an impact on how random forest performs vs. bagging. Think of our CIFAR-10 dataset. Bagging takes a LOT longer to run than random forest because bagging will have to test all 3072 features for each tree branch to find the best feature. But random forest only has to test 55 features – the square root of 3072! \n",
    " \n",
    "In Assignment 5 the following random forest model building 1000 trees had a test score of 0.4937 and took about 3 minutes to run (on my computer):\n",
    "\n",
    "     RandomForestClassifier(n_jobs=-1, random_state=42, n_estimators=1000)\n",
    "\n",
    "Yet a bagging model that builds only 100 trees takes about 20 minutes, so imagine how long it would take if we did bagging with 1000 trees!  In the next cell we will try a modification to a pure bagging model that still takes time, but should give us better accuracy than pure bagging.  It's called a 'random patches' model.\n",
    "\n",
    "Regarding Random Patches, Géron writes that, \"This technique is particularly useful when you are dealing with high-dimensional inputs (such as images)... Sampling features results in even more predictor diversity, trading a bit more bias for a lower variance.\"\n",
    "\n",
    "Since we are working with images, it sounds like this algorithm is a good candidate for us to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b050ea-cb1b-426a-a68b-cc815137f5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2: 10 points \n",
    "\n",
    "# Random Patches Bagging\n",
    "# To modify a pure bagging model to a random patches bagging model, just add this  \n",
    "# parameter to the call to BaggingClassifier: bootstrap_features=True\n",
    "\n",
    "# Because bagging models, including random patches, are quite slow we will \n",
    "# add a timer and a call to playsound to let us know when it's finished.\n",
    "\n",
    "# 5 points: Define a random patches model by calling BaggingClassifier with \n",
    "#           bootstrap_features, a random state of 42, and set n_jobs to use\n",
    "#           all available cores, but have it build only 50 trees. Also add\n",
    "#           verbose=True so you can track the training progress. Save this random\n",
    "#           patches model in the the variable rndPatches\n",
    "# 2 points: Fit the model on the training data.\n",
    "# 1 point:  Add a line of code to print the model's score on the test data.\n",
    "# 2 points: Add the code from previous assignments that you need to calculate and display\n",
    "#           this model's time, and also to notify yourself when it's done with playsound.\n",
    "\n",
    "####################  insert your code below for 10 points ####################\n",
    "\n",
    "   \n",
    "\n",
    "rndPatches = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### Your code ends above ##############################\n",
    "\n",
    "# On my computer this took 12 mins and had accuracy of 0.4507\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6b467-d548-438f-9b04-5f4104f06a67",
   "metadata": {},
   "source": [
    "#### On the same number of trees Random Patches is indeed more accurate on CIFAR-10 than random forest. \n",
    "\n",
    "On my laptop the score with 100 trees (instead of the 50 we just did) is 0.4695, but at the cost of 21 minutes. Of course, we are not overly excited about 0.4695 because when we built a random forest model with unlimited depth and 1000 trees, we obtained 49.37% accuracy as noted above.\n",
    "\n",
    "However, Géron points out yet another variation to bagging that he refers to as 'Extremely Randomized Trees' that uses ExtraTreesClassifier.  This approach has a significant difference from both Random Forest and Bagging that dramatically reduces the compute time.  Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea202da-00fd-41fc-bf4a-232308e15c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3: 10 points     \n",
    "\n",
    "# See Géron's ch.7 section on 'Extra Trees' where, again, \n",
    "# we see the trade off of adding more bias for reduced variance.\n",
    "# Let's try it with the same settings we used for our best model\n",
    "# yet, which was the 1000 tree random forest that got 0.4937 and\n",
    "# took only about 3 minutes to run (again, on my computer).\n",
    "\n",
    "# 5 points:  Use ExtraTreesClassifier to build an ensemble\n",
    "#            of 1000 trees, with no maximum depth, using a\n",
    "#            random state of 42 and all available CPU cores.\n",
    "#            Save the model into variable xRndTrees\n",
    "# 1 point:   Train xRndTrees\n",
    "# 1 point:   Evaluate xRndTrees on the test data and print\n",
    "#            that score with an appropriate explanatory message\n",
    "# 3 points:  Add the timing code and playsound.\n",
    "\n",
    "####################  insert your code below for 10 points ####################\n",
    "\n",
    "\n",
    "\n",
    "xRndTrees = \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### Your code ends above ##############################\n",
    "\n",
    "# 0.4965, indeed better than the rf model we did earlier with exactly the same parameter settings\n",
    "# and at just over 2 mins, is not only MUCH faster than Bagging but also about 1/3 FASTER than the rf \n",
    "# This is now our best model so far.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69773575-da45-488d-859b-6b2a4803a2b7",
   "metadata": {},
   "source": [
    "#### Exploring Feature Importance\n",
    "With the ExtraTreesClassifier (and also with RandomForestClassifier, but not bagging models) you can get some very interesting information about the features of your trained model. There is a parameter you can inspect after training that indicates the relative importance of each feature in your training data.  In Fig. 7-6 of Géron, there is a visualization (left) of the the feature importance for a digit.  The image on the right is a similar one I created for the CIFAR-10 images:\n",
    "\n",
    "<img src='mnist_feature_importance_plot.png' width=\"400\" height=\"400\"> <img src='cifar10_feature_importance_plot.png' width=\"420\" height=\"420\">\n",
    "\n",
    "Not only are the bright pixels the ones that often carry the most useful information, but it's also interesting to notice how many completely or nearly black pixels there are.  Those indicate relatively useless features.  I will return to this point shortly.  But first, let's see how we created the image for CIFAR-10 on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-acrylic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 4: 10 points  \n",
    "\n",
    "# In both images above there is a 2-dimensional matrix where each value\n",
    "# represents the importance of the pixel that corresponds to that row, column.\n",
    "# The code below is for the image on the right, but we are using color images, \n",
    "# not black & white which was used for the image on the left, and each \n",
    "# RGB channel has its own feature importance value.\n",
    "\n",
    "# Read what Géron writes about feature_importances_ as he discusses Figure 7-6 \n",
    "# and you may realize that what WE need is not a shape of (32, 32, 3) but a shape \n",
    "# of (32, 32) whose values are the SUM of the 3 real numbers in the 3rd dimension.\n",
    "\n",
    "# I have written most of the code for you. Your code will be inserted into\n",
    "# the body of a LOCAL function called 'addRGB' that is enclosed by a function\n",
    "# called 'plotPixelImportance'.  If you have never defined such a local \n",
    "# function before, it just means that you can ONLY call that local function\n",
    "# from inside the enclosing function.  If you try to call it outside\n",
    "# of the enclosing function, you'll get an error.\n",
    "\n",
    "# Here are the points for your code:\n",
    "# 3 points:  Initialize a numpy matrix in the shape of 32 by 32 since our images\n",
    "#            have that many pixels (32 * 32 = 1024 pixels). Set the initial\n",
    "#            values of this matrix to all zeros. (Use Google if you don't\n",
    "#            know how to create a numpy matrix initialized to zeros.) Save the\n",
    "#            matrix into the variable 'newImg'\n",
    "# 5 points:  write Python code to replace each 0 in newImg with the sum of\n",
    "#            the 3 numbers in the third dimension of 'img', which is the \n",
    "#            argument to the local function addRGB. Think about  \n",
    "#            the shape of the img argument, and how you can access\n",
    "#            its third dimension. (Google is your friend) It may help\n",
    "#            to create a temporary notebook cell, manually build a small\n",
    "#            matrix of shape (2, 3, 3) with random numbers, and test out\n",
    "#            some code, then recycle that code here when its working.\n",
    "#            Hint: one solution is to use an outer loop that iterates\n",
    "#            over matrix rows and an inner loop iterating over columns.\n",
    "#  2 points: Return the modified newImg matrix as the value of the local \n",
    "#            function addRGB\n",
    "\n",
    "# It may also help you to READ the code below, especially the reshape code \n",
    "# beneath the local function before you begin.\n",
    "\n",
    "def plotPixelImportance(data):\n",
    "    # This is Géron's function for Fig. 7-6, modified for the CIFAR10 dataset.\n",
    "    # Plot a heatmap of the importance for classification of the 1024 pixels,\n",
    "    # where each pixel has 3 color channels \n",
    "    \n",
    "    # 'data' is a color image with shape (32, 32, 3)\n",
    "    def addRGB(img):\n",
    "        '''Convert the 'data' shape(32, 32, 3) to the newImg shape(32, 32) by adding \n",
    "           the numbers in the 3rd dimension of 'data' and putting their sum into \n",
    "           each row/column pixel of newImg'''\n",
    "        \n",
    "######################### Add your code below, about 5 lines or so ##########################\n",
    "        \n",
    "        newImg =  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "#################################### Your code ends above ###################################\n",
    "    \n",
    "    image    = data.reshape(32, 32, 3) # restore to original shape of images\n",
    "    imageNew = addRGB(image)           # convert to shape(32, 32) by adding \n",
    "                                       # the feature importance values in the 3rd dimension\n",
    "    plt.imshow(imageNew, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    return(imageNew)\n",
    "\n",
    "heatMap = plotPixelImportance(xRndTrees.feature_importances_)\n",
    "cbar    = plt.colorbar(ticks=[xRndTrees.feature_importances_.min(), \n",
    "                              xRndTrees.feature_importances_.max()])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e9c9f-eb11-403e-b001-852688eb705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: 10 points     \n",
    "# Chapter 9 is about unsupervised methods to explore data.\n",
    "# One of the most common algorithms is K-Means, which is used\n",
    "# to find naturally occurring clusters of data.  For example,\n",
    "# since we are analyzing 10 categories of different pictures,\n",
    "# it would be reasonable to ask if each of those 10 categories \n",
    "# somehow forms a natural cluster.  KMeans can help expore that\n",
    "# hypothesis. \n",
    "\n",
    "# KMeans is a very fast algorithm and it groups data instances\n",
    "# by how similar they are, where similarity is generally based\n",
    "# on Euclidean distance. (See Géron and my lecture for details.)\n",
    "\n",
    "# So let's create a KMeans clustering of the CIFAR-10 data.\n",
    "# We will use only 5000 images, which should include about \n",
    "# 500 of each category.\n",
    "\n",
    "# KMeans is UNsupervised, and does not know in \n",
    "# advance how many (or even if) natural clusters exist. Hence,\n",
    "# there is a hyperparameter that controls how many clusters\n",
    "# are created. It is common to tune this n_clusters hyperparameter\n",
    "# and analyze the results to determine the optimal number\n",
    "# of clusters to create.  But since we already know there are\n",
    "# 10 categories in CIFAR-10, we will simply set n_clusters=10\n",
    "# and let it run.  Let's see if it shows anything interesting.\n",
    "\n",
    "# 3 points: Use the preset variable numImages to extract\n",
    "#           that number of images from X_train_flat and save them\n",
    "#           into the variable cifarImgs\n",
    "# 2 points: Save the corresponding labels for those images\n",
    "#           into the variable cifarLabels (we will use that variable\n",
    "#           below in another cell, not this cell) Be careful here!\n",
    "#           Do not simply get the value of LABEL_NAMES.  Those are\n",
    "#           string labels like 'cat'.  The true labels, which are\n",
    "#           integers, are the values of y_train.\n",
    "#           You want the labels that match the cifarImgs that you \n",
    "#           just did.  So you can actually get those labels in\n",
    "#           a similar manner by using y_train\n",
    "# 3 points: Create a KMeans model and use the preset numClusters\n",
    "#           to tell KMeans how many clusters to create with \n",
    "#           a random state of 16 (NOT 42 or any other number!)\n",
    "#           Use the URL at the beginning of this notebook to \n",
    "#           find the parameter name to set with numClusters\n",
    "#           Save your model into the variable km         \n",
    "# 2 points: Call the km model's fit method on cifarImgs\n",
    "\n",
    "######################### Add your code below ##########################\n",
    "\n",
    "numImages   = 5000 # you can try different values if you like\n",
    "numClusters = 10   # do not change this parameter for the assignment\n",
    "cifarImgs   =                           # get 1st numImages train images\n",
    "cifarLabels =                           # and their labels. This\n",
    "                                        # var will be used later in\n",
    "                                        # the notebook\n",
    "km          = \n",
    "\n",
    "\n",
    "\n",
    "######################## Your code ends above ##########################\n",
    "\n",
    "# In the next cell we will inspect this model to get\n",
    "# insight into how good it is\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1498d7-e14e-473e-8121-31af8dc5c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: 10 points   \n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "# The Silhouette Score (described in Géron) is a good way \n",
    "# to evaluate how good a KMeans cluster is.\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "# In the text and lecture, you will remember that a Silhouette score \n",
    "# close to 1 means that the clusters are well separated, which is good. \n",
    "# If close to -1 they're NOT, and close to 0 means there is a lot\n",
    "# of ambiguity in the cluster assignments of data observations.\n",
    "\n",
    "# We will use the yellowbrick implementation for Silhouette scores\n",
    "# because it is so easy to use. In contrast, go look at Géron's code\n",
    "# in his chapter 9 notebook and notice how much work it would be to\n",
    "# modify it to do what we want here.\n",
    "\n",
    "# 2 points: Define the same KMeans model as in the previous cell and save it in kmYB\n",
    "# 3 points: Call yellowbrick's SilhouetteVisualizer and pass it kmYB, \n",
    "#           colors='yellowbrick' and size=(960, 640)\n",
    "#           Save the visualizer in ybViz\n",
    "# 3 points: Call the fit method of ybViz on cifarImgs, similar to km.fit in the previous cell\n",
    "# 2 points: Call the show method of ybViz\n",
    "\n",
    "######################### Add your code below ##########################\n",
    "\n",
    "print('\\nThe Silhouette Score is:', silhouette_score(cifarImgs, km.labels_))  \n",
    "# labels_ tells us which cluster each observation was assigned to\n",
    "\n",
    "kmYB  =                                                 # Create same KMeans model because training\n",
    "                                                        # needs to happen in scope of the visualizer\n",
    "ybViz = \n",
    "\n",
    "                                                       \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "######################## Your code ends above ##########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f570692-5846-4ea3-8125-123654d3f794",
   "metadata": {},
   "source": [
    "#### Oops, KMeans doesn't really do so well on the CIFAR-10 data, does it?  \n",
    "\n",
    "The Silhouette Score so close to zero tells us that it's bad.  The Silhouette visualization confirms it, and also provides a bit of explanation because notice how many of the clusters have a significant portion of their observations with negative-valued silhouette coefficients.  While KMeans does not work well on this particular dataset (it does for many others), we will build one more KMeans model so we can see something else that is interesting. But first, let's do a short extra credit task for 5 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa437f86-c249-46f0-99bf-f3e750f8a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: 5 EXTRA CREDIT points   \n",
    "\n",
    "# Before we decide to move on from KMeans, let's do a bit more.  \n",
    "# know that it doesn't work well on the raw CIFAR-10 data, but aren't\n",
    "# you curious to know more?\n",
    "\n",
    "# First of all, look how easy it is to extract the 'inertia' from\n",
    "# a KMeans model:\n",
    "print('Inertia:\\t', km.inertia_) \n",
    "\n",
    "# You'll remember that this metric measures the average squared distance\n",
    "# between each data point and its closest centroid.  Since tight\n",
    "# clusters are desired, this means that an inertia close to 0 is \n",
    "# also desired.  When you run this cell you'll see the inertia.\n",
    "# But we won't know if the number displayed is good or bad\n",
    "# since we have nothing to compare it to.  We did not try other\n",
    "# values of k.  But there are other metrics that may be useful\n",
    "# to us.\n",
    "\n",
    "# If you know what the ground truth labels are for your data (and we do, \n",
    "# even though we did not use that info for the last two tasks),\n",
    "# then here are two more metrics that can give a bit more insight:\n",
    "#    homogeneity:  each cluster contains only members of a single class.\n",
    "#    completeness: all members of a given class are assigned to the same cluster.\n",
    "# Both of these range from 0 to 1 with 1 being the best possible.\n",
    "\n",
    "# These are not discussed by Géron, but the sklearn documentation for homogeneity is at:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html?highlight=homogeneity_score\n",
    "# and completeness is here:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score\n",
    "\n",
    "# We can also extract these metrics as long as we provide the \n",
    "# ground truth labels, which (if you did it correctly in Task 5) are already\n",
    "# in the variable 'cifarLabels'\n",
    "\n",
    "# KMeans has a 'predict' method, even though it is not a supervised\n",
    "# learning algorithm.  It will simply predict the most appropriate cluster\n",
    "# assignment for its argument based on the trained KMearns model. We can\n",
    "# use it here to predict the clusters on the cifarImgs that were used\n",
    "# to created the KMeans model itself.\n",
    "\n",
    "# 3 points: Use the 'km' model from Task 5 to predict the class assignments\n",
    "#           for the cifarImgs.  Save those predictions into predictedLabels\n",
    "# 1 point:  Call the homogeneity_score function, passing it the two \n",
    "#           arguments cifarLabels that you set in Task 5, and\n",
    "#           predictedLabels that you just set moments ago.  Put that code\n",
    "#           as the 2nd argument to the first print statement below.\n",
    "# 1 point:  Call the completeness_score function, passing it the same two\n",
    "#           arguments that you used for homogeneity.  Put that code\n",
    "#           as the 2nd argument to the second print statement below. \n",
    "######################### Add your code below ##########################\n",
    "\n",
    "predictedLabels = \n",
    "\n",
    "print('Homogeneity:\\t',  )\n",
    "print('Completeness:\\t', )\n",
    "\n",
    "######################### Add your code above  ##########################\n",
    "\n",
    "# Assuming you also see these latter two metrics near 0.09 it would\n",
    "# appear that KMeans may be hopeless. But let's try something else \n",
    "# before we stop using KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdf46f-c44f-4982-838c-5ccf90f5f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: 10 points   \n",
    "\n",
    "# As you know, we skipped chapter 8, but I want to show you\n",
    "# what is possible with its techniques so you may be\n",
    "# interested enough to read the whole chapter.\n",
    "# With our CIFAR-10 data each of the 32 by 32 pixels\n",
    "# has 3 colors, so when we flatten that shape (32, 32, 3) \n",
    "# matrix we end up with 3072 numbers in a vector.  Each number\n",
    "# will be treated as a feature by any ML algorithm.  That is not\n",
    "# only a lot of features, but we saw in the feature importance\n",
    "# color map above that many of those features are not\n",
    "# actually very important.  Is there some way we can convert\n",
    "# those 3072 features into a smaller number of features\n",
    "# such that the new ones ARE ALL important?  \n",
    "\n",
    "# Yes there is, and we will use dimension reduction from Chapter 8 \n",
    "# to do so. The most common dimension reduction algorithm is called \n",
    "# Principal Component Analysis, or PCA for short.  We were unable\n",
    "# to visualize the clusters of our KMeans algorithm above \n",
    "# because there is no way to plot 3072 features on a 2-dimensional\n",
    "# computer screen.  But using PCA we can reduce them down to only 2\n",
    "# features, which we CAN plot.  In fact, it's easy to do.\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# I have written some of the code below for you,\n",
    "# but there are still some lines to complete.  \n",
    "# For 10 points total:\n",
    "#   3 points: Call PCA and pass it 2 arguments: \n",
    "#        the first is the number of principal components \n",
    "#        that we want, which is 2, so we can plot it.  \n",
    "#        So set n_components to 2 as your first argument.  \n",
    "#        Also set random_state to 2 and use that as the 2nd argument.\n",
    "#        Save the value of that PCA definition into pcaData\n",
    "#   2 points: Now call the fit_transform method of PCA with cifarImgs, \n",
    "#        which will perform the actual PCA transformation of the 3072\n",
    "#        features down to only 2! (the most important 2, by the way)\n",
    "#        Save this value back into the variable pcaData\n",
    "#   2 points: I have defined the same KMeans model as we used earlier\n",
    "#        and saved it in variable kmPCA.  So now call its fit method\n",
    "#        with pcaData instead of the original cifarImgs data\n",
    "#   3 points: Call the plotting function defined near the top of this\n",
    "#        notebook, passing it both kmPCA and pcaData as arguments.\n",
    "#        This plotting function is called plot_decision_boundaries\n",
    "\n",
    "\n",
    "######################### Add your code below ##########################\n",
    "\n",
    "pcaData = \n",
    "pcaData = \n",
    "\n",
    "print('\\n Confirm we have 5000 rows but only 2 columns now:', pcaData.shape)\n",
    "\n",
    "pcaData = pcaData.astype('double')                        # If this is omitted, you\n",
    "                                                          # will see a data type error\n",
    "kmPCA   = KMeans(n_clusters=numClusters, random_state=16) # Same model we used above\n",
    "\n",
    "\n",
    "# Put your code to fit kmPCA on pcaData AFTER this comment:\n",
    "  \n",
    "\n",
    "# Let's now look at the Voroni visualization using the functions\n",
    "# defined near the top of this notebook.\n",
    "# The red dots inside a white circle show the location of the cluster centers\n",
    "\n",
    "# Put your call to plot_decision_boundaries AFTER this comment, but\n",
    "# BEFORE the call to plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()  # This will show the Voroni visualization with boundaries\n",
    "\n",
    "######################## Your code ends above ##########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66268949-39f9-414f-907c-e706af2d553a",
   "metadata": {},
   "source": [
    "In this Voroni visualization the red dots inside white circles are the locations of the cluster centers. If you are wondering why I had you use random_state = 16 for the KMeans model and random_state = 2 for the PCA data, it's because of some weirdness in this Voroni visualization.  With other random states it doesn't draw all of the boundaries properly.  I don't know why.  It's Géron's code and I didn't study it that carefully.\n",
    "\n",
    "The point of this task is to show you that you can use PCA dimensionality reduction to shrink large dimensional data down to 2 dimensions, which then allows you to visualize it.  Pretty cool, huh?  But notice another thing:  The plotted points don't really appear visually as 10 distinct clusters.  If your ignore the class boundary lines, you can see it simply looks like one big cluster.  That is why our Silhouette Score was so bad and why the Silhouette visualization earlier also looked bad. \n",
    "\n",
    "I think one reason for this is due to the large dimensionality, as well as the diversity of images even of the same object.  Not all cats or boats look the same as others, and many images are from different angles or viewpoints, hence the location of the image in high-dimensional space varies quite a lot, even for the same category.  This explanation also makes sense given that we still haven't found a classifier that gives us even 50% accuracy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65153d-6d29-4550-b013-a9618f0cca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 9: 10 points \n",
    "\n",
    "# Let's see what else we can do with PCA. We'll use what you just \n",
    "# learned about building a pca-reduced model, but we'll do more \n",
    "# than 2 features. This time, however, instead of calling \n",
    "# the fit_transform method as we did above, we will fit the data \n",
    "# and then transform it separately.  I'll explain why below.\n",
    "\n",
    "# 2 points: Build a PCA model that creates 40 PCA components with a\n",
    "#           random state of 42. (Yes, we are returning to 42 now.)\n",
    "#           Save it into pca40\n",
    "# 2 points: Call the fit  method on pca40, but this time\n",
    "#           call it on ALL of X_train_flat. Do not save the results\n",
    "#           into any variable.  \n",
    "# 1 point:  Call the transform method of the fitted pca40 model,\n",
    "#           passing it X_train_flat, but now save THIS result\n",
    "#           into the new variable X_train_PCA\n",
    "# 1 point:  Also transform the TEST data X_test_flat by \n",
    "#           calling the transform method of pca40 a second time,\n",
    "#           saving the result into X_test_PCA\n",
    "\n",
    "# This is why we separated the fit from the transform this time.\n",
    "# It is CRUCIALLY IMPORTANT to apply any data transformations on\n",
    "# your test data in an IDENTICAL way to your transformations of your \n",
    "# training data to avoid data snooping.\n",
    "\n",
    "# After you have added your code for these parts, there are 2 print \n",
    "# statements. If you do not see 40 columns in both X_train_PCA and \n",
    "# X_test_PCA then you have done something wrong in the previous steps.\n",
    "\n",
    "# Continue with more code after the print statements by building\n",
    "# a new ExtraTreesClassifier in the following way:\n",
    "\n",
    "# 2 points: Copy the ExtraTreesClassifier definition from Task 3\n",
    "#           and save it into the variable pcaXTrees\n",
    "# 2 points: Train pcaXTrees on X_train_PCA and y_train \n",
    "\n",
    "# When you run this cell, there are 2 more lines of code at the\n",
    "# bottom that will evaluate your new model and print the test\n",
    "# data score.  If you have done this correctly, you should see\n",
    "# a new accuracy that is better than 50% for the first time!\n",
    "\n",
    "######################### Add your code below ##########################\n",
    "\n",
    "pca40 = \n",
    "\n",
    "\n",
    "\n",
    "X_train_PCA =                               # Apply PCA reduction to both train \n",
    "X_test_PCA  =                               # and test data\n",
    "\n",
    "print(X_train_PCA.shape)\n",
    "print(X_test_PCA.shape)\n",
    "\n",
    "pcaXTrees   = \n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "######################## Your code ends above ##########################\n",
    "\n",
    "testAcc = pcaXTrees.score(X_test_PCA, y_test)\n",
    "print('\\nTest accuracy of extremely randomized trees with 40 principal components:', testAcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59804e9-0aa0-4e83-8b40-02b90a6ca033",
   "metadata": {},
   "source": [
    "Assuming you got the expected results, your model should be a bit higher than 51% test accuracy! This is because those first 40 principal components account for about 80% of the variance in the data (I determined that by doing some separate analysis that I did not include here.)  What that means is that we have taken 3072 features, many of which carried little useful information, and reduced them down to 40 features which carry excellent information. That's why we got better results.  This will not happen every time for every dataset where you use PCA, but when you have high dimensional data and you are getting disappointing results, try PCA and you may very well see an improvement.  We are almost done.  \n",
    "\n",
    "Run the next cell where we take the first THREE of the 40 principal components from our pcaXTrees model and use that 3rd component as a third dimension to display a 3-D visualization of the 10000 test data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c252dd-7341-4da0-bb99-eaec400dd466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "points_to_plot = 10000\n",
    "\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax  = fig.add_subplot(111, projection=\"3d\", elev=30, azim=134) \n",
    "\n",
    "ax.set_position([0, 0, 0.95, 1])\n",
    "\n",
    "ax.scatter(X_test_PCA[0:points_to_plot, 0], \n",
    "           X_test_PCA[0:points_to_plot, 1], \n",
    "           X_test_PCA[0:points_to_plot, 2], \n",
    "           c         = y_test[0:points_to_plot], \n",
    "           cmap      = plt.cm.nipy_spectral, \n",
    "           edgecolor =\"k\")\n",
    "\n",
    "plt.title('First 3 Principal Components \\nTest accuracy = {:.4f}'.format(testAcc))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb309f-e86a-4d16-8fac-5c7194ad95b0",
   "metadata": {},
   "source": [
    "### I hope you are now encouraged to read chapter 8 after the class is over.  Keep learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
